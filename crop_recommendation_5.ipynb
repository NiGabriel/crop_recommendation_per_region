{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_data = pd.read_excel('datasets/crop_recommendation_new.xlsx', sheet_name=0)\n",
    "region_data = pd.read_excel('datasets/202408_KI_Database (soil, crop, location, etc).xlsx', sheet_name=0)\n",
    "test_data = pd.read_excel('datasets/crop_recommendation_new.xlsx', sheet_name=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning crop data\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the unnecessary space\n",
    "crop_data.columns = crop_data.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sectors_per_district = region_data['District'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_potassium_range(potassium_range):\n",
    "    if isinstance(potassium_range, str):  # Ensure it's a string\n",
    "        potassium_range = potassium_range.strip()  # Clean up leading/trailing spaces\n",
    "        \n",
    "        if '<' in potassium_range:\n",
    "            upper_bound = float(potassium_range.split('<')[-1].strip())\n",
    "            # Calculate the average of 0 and the upper bound\n",
    "            return (0, (0 + upper_bound) / 2)\n",
    "        elif '>' in potassium_range:\n",
    "            lower_bound = float(potassium_range.split('>')[-1].strip())\n",
    "            # Use an arbitrary high value to compute average, like double the lower_bound\n",
    "            return (lower_bound, (lower_bound + lower_bound * 2) / 2)\n",
    "        elif '-' in potassium_range:\n",
    "            return tuple(map(float, potassium_range.split('-')))\n",
    "        else:\n",
    "            return (float(potassium_range), float(potassium_range))\n",
    "    else:\n",
    "        # Handle case where input is already a float\n",
    "        return (float(potassium_range), float(potassium_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pH_range(ph_range):\n",
    "    if isinstance(ph_range, str):  # Ensure it's a string\n",
    "        ph_range = ph_range.strip()  # Clean up leading/trailing spaces\n",
    "        \n",
    "        if '<' in ph_range:\n",
    "            upper_bound = float(ph_range.split('<')[-1].strip())\n",
    "            # Calculate the average of 0 and the upper bound\n",
    "            return (0, (0 + upper_bound) / 2)\n",
    "        elif '>' in ph_range:\n",
    "            lower_bound = float(ph_range.split('>')[-1].strip())\n",
    "            # Use an arbitrary high value to compute average, like double the lower_bound\n",
    "            return (lower_bound, (lower_bound + lower_bound * 2) / 2)\n",
    "        elif '-' in ph_range:\n",
    "            return tuple(map(float, ph_range.split('-')))\n",
    "        else:\n",
    "            return (float(ph_range), float(ph_range))\n",
    "    else:\n",
    "        # Handle case where input is already a float\n",
    "        return (float(ph_range), float(ph_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_phosphorus_range(p_range):\n",
    "    if isinstance(p_range, str):\n",
    "        if '<' in p_range:\n",
    "            upper_bound = float(p_range.split('<')[-1].strip())\n",
    "            # Calculate the average of 0 and the upper bound\n",
    "            return (0, (0 + upper_bound) / 2)\n",
    "        elif '>' in p_range:\n",
    "            lower_bound = float(p_range.split('>')[-1].strip())\n",
    "            # Use an arbitrary high value to compute average, like double the lower_bound\n",
    "            return (lower_bound, (lower_bound + lower_bound * 2) / 2)\n",
    "        elif '-' in p_range:\n",
    "            return tuple(map(float, p_range.split('-')))\n",
    "        else:\n",
    "            return (float(p_range), float(p_range))\n",
    "    else:\n",
    "        return (float(p_range), float(p_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_humidity_range(humidity_range):\n",
    "    if isinstance(humidity_range, str):\n",
    "        if '<' in humidity_range:\n",
    "            upper_bound = float(humidity_range.split('<')[-1].strip())\n",
    "            # Calculate the average of 0 and the upper bound\n",
    "            return (0, (0 + upper_bound) / 2)\n",
    "        elif '>' in humidity_range:\n",
    "            lower_bound = float(humidity_range.split('>')[-1].strip())\n",
    "            # Use an arbitrary high value to compute average, like double the lower_bound\n",
    "            return (lower_bound, (lower_bound + lower_bound * 2) / 2)\n",
    "        elif '-' in humidity_range:\n",
    "            return tuple(map(float, humidity_range.split('-')))\n",
    "        else:\n",
    "            return (float(humidity_range), float(humidity_range))\n",
    "    else:\n",
    "        return (float(humidity_range), float(humidity_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_temperature_range(temp_range):\n",
    "    if isinstance(temp_range, str):\n",
    "        if '<' in temp_range:\n",
    "            upper_bound = float(temp_range.split('<')[-1].strip())\n",
    "            # Calculate the average of 0 and the upper bound\n",
    "            return (0, (0 + upper_bound) / 2)\n",
    "        elif '>' in temp_range:\n",
    "            lower_bound = float(temp_range.split('>')[-1].strip())\n",
    "            # Use an arbitrary high value to compute average, like double the lower_bound\n",
    "            return (lower_bound, (lower_bound + lower_bound * 2) / 2)\n",
    "        elif '-' in temp_range:\n",
    "            return tuple(map(float, temp_range.split('-')))\n",
    "        else:\n",
    "            return (float(temp_range), float(temp_range))\n",
    "    else:\n",
    "        return (float(temp_range), float(temp_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_soil_moisture_range(moisture_range):\n",
    "    if isinstance(moisture_range, str):\n",
    "        if '<' in moisture_range:\n",
    "            upper_bound = float(moisture_range.split('<')[-1].strip())\n",
    "            # Calculate the average of 0 and the upper bound\n",
    "            return (0, (0 + upper_bound) / 2)\n",
    "        elif '>' in moisture_range:\n",
    "            lower_bound = float(moisture_range.split('>')[-1].strip())\n",
    "            # Use an arbitrary high value to compute average, like double the lower_bound\n",
    "            return (lower_bound, (lower_bound + lower_bound * 2) / 2)\n",
    "        elif '-' in moisture_range:\n",
    "            return tuple(map(float, moisture_range.split('-')))\n",
    "        else:\n",
    "            return (float(moisture_range), float(moisture_range))\n",
    "    else:\n",
    "        return (float(moisture_range), float(moisture_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and convert the pH column in crop_data\n",
    "def convert_crop_ph(ph_value):\n",
    "    if isinstance(ph_value, str) and '-' in ph_value:\n",
    "        # If pH is in range format \"6.0-7.0\", convert it to the midpoint\n",
    "        ph_min, ph_max = map(float, ph_value.split('-'))\n",
    "        return (ph_min + ph_max) / 2  # Using the average of the range\n",
    "    else:\n",
    "        return float(ph_value)  # Ensure single values are floats\n",
    "\n",
    "crop_data['pH'] = crop_data['pH'].apply(convert_crop_ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean the range values or '>' values\n",
    "def clean_range_or_greater_than(value):\n",
    "    if isinstance(value, str):\n",
    "        if '-' in value:\n",
    "            # If the value is a range (e.g., '680-1400'), calculate the midpoint\n",
    "            value_min, value_max = map(float, value.split('-'))\n",
    "            return (value_min + value_max) / 2\n",
    "        elif '>' in value:\n",
    "            # If the value starts with '>' (e.g., '>4500'), remove the '>' and return the numeric part\n",
    "            return float(value.replace('>', '').strip())\n",
    "    # If the value is already a number (or can be converted), just return it\n",
    "    try:\n",
    "        return pd.to_numeric(value, errors='coerce')\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning function to the relevant columns\n",
    "crop_data['Altitude (masl)'] = crop_data['Altitude (masl)'].apply(clean_range_or_greater_than)\n",
    "crop_data['Annual rainfall (mm)'] = crop_data['Annual rainfall (mm)'].apply(clean_range_or_greater_than)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse the humidity range from strings like '60-70' to numerical min and max\n",
    "def parse_humidity_range(humidity_range):\n",
    "    # Convert to string if it's not already, and handle cases where it might be NaN or a float\n",
    "    if isinstance(humidity_range, float) or pd.isna(humidity_range):\n",
    "        return None, None\n",
    "    try:\n",
    "        min_value, max_value = map(float, str(humidity_range).split('-'))\n",
    "        return min_value, max_value\n",
    "    except ValueError:\n",
    "        # If the split fails, return None for both values\n",
    "        return None, None\n",
    "\n",
    "# Apply the parsing function to create min and max columns in crop_data\n",
    "crop_data[['Humidity_min', 'Humidity_max']] = crop_data['Humidity(%)'].apply(\n",
    "    lambda x: pd.Series(parse_humidity_range(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse the humidity range from strings like '60-70' to numerical min and max\n",
    "def parse_temperature_range(temperature_range):\n",
    "    # Convert to string if it's not already, and handle cases where it might be NaN or a float\n",
    "    if isinstance(temperature_range, float) or pd.isna(temperature_range):\n",
    "        return None, None\n",
    "    try:\n",
    "        min_value, max_value = map(float, str(temperature_range).split('-'))\n",
    "        return min_value, max_value\n",
    "    except ValueError:\n",
    "        # If the split fails, return None for both values\n",
    "        return None, None\n",
    "\n",
    "# Apply the parsing function to create min and max columns in crop_data\n",
    "crop_data[['Temperature_min', 'Temperature_max']] = crop_data['temperature (C)'].apply(\n",
    "    lambda x: pd.Series(parse_temperature_range(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse the humidity range from strings like '60-70' to numerical min and max\n",
    "def parse_moisture_range(moisture_range):\n",
    "    # Convert to string if it's not already, and handle cases where it might be NaN or a float\n",
    "    if isinstance(moisture_range, float) or pd.isna(moisture_range):\n",
    "        return None, None\n",
    "    try:\n",
    "        min_value, max_value = map(float, str(moisture_range).split('-'))\n",
    "        return min_value, max_value\n",
    "    except ValueError:\n",
    "        # If the split fails, return None for both values\n",
    "        return None, None\n",
    "\n",
    "# Apply the parsing function to create min and max columns in crop_data\n",
    "crop_data[['Moisture_min', 'Moisture_max']] = crop_data['Optimum soil moisture'].apply(\n",
    "    lambda x: pd.Series(parse_moisture_range(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert ranges into mean values\n",
    "def convert_to_mean(value):\n",
    "    if isinstance(value, float) or pd.isna(value):\n",
    "        # If the value is already a float (or NaN), return it as is\n",
    "        return value\n",
    "    elif '-' in value:\n",
    "        # If the value contains a range like \"500-700\", compute the mean\n",
    "        low, high = value.split('-')\n",
    "        return (float(low) + float(high)) / 2\n",
    "    elif '>' in value:\n",
    "        # If the value contains \">\", return the minimum possible value plus a small buffer (e.g., 50)\n",
    "        return float(value.replace('>', '').strip()) + 50\n",
    "    else:\n",
    "        # For single values, return as float\n",
    "        return float(value.strip())\n",
    "\n",
    "# Apply conversion to 'Annual rainfall (mm)' column\n",
    "crop_data['Annual rainfall (mm)'] = crop_data['Annual rainfall (mm)'].apply(convert_to_mean)\n",
    "\n",
    "# Apply conversion to 'Irrigation required(%)' column\n",
    "crop_data['Irrigation required(%)'] = crop_data['Irrigation required(%)'].apply(convert_to_mean)\n",
    "\n",
    "# Apply conversion to 'Crop water need (mm/total growing period)' column\n",
    "crop_data['Crop water need (mm/total growing period)'] = crop_data['Crop water need (mm/total growing period)'].apply(convert_to_mean)\n",
    "\n",
    "# Apply conversion to 'Growing period (days)' column\n",
    "crop_data['Growing period (days)'] = crop_data['Growing period (days)'].apply(convert_to_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping similar soil types to common categories\n",
    "soil_mapping = {\n",
    "    r'.*well[-\\s]*drain.*': 'Well-drained',\n",
    "    r'.*sandy.*loam.*': 'Sandy Loam',\n",
    "    r'.*loam.*clay.*': 'Clay Loam',\n",
    "    r'.*loamy.*': 'Loamy',\n",
    "    r'.*sandy.*': 'Sandy',\n",
    "    r'.*volcanic.*': 'Volcanic',\n",
    "    r'.*alluvial.*': 'Alluvial'\n",
    "}\n",
    "\n",
    "# Clean the 'Soil type' column using regex mapping\n",
    "crop_data['Soil type'] = crop_data['Soil type'].str.lower()\n",
    "for pattern, replacement in soil_mapping.items():\n",
    "    crop_data['Soil type'] = crop_data['Soil type'].str.replace(pattern, replacement, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split rows with multiple start/end months into separate rows\n",
    "def expand_crop_calendar(crop_data):\n",
    "    rows = []\n",
    "    for _, row in crop_data.iterrows():\n",
    "        # Convert to string if it's not already, and replace NaN with an empty string\n",
    "        start_months = str(row['Crop calendar start (month)']).replace(' ', '').split(',')\n",
    "        end_months = str(row['Crop calendar end (month)']).replace(' ', '').split(',')\n",
    "\n",
    "        # Ensure we match start and end seasons properly\n",
    "        for start, end in zip(start_months, end_months):\n",
    "            new_row = row.copy()\n",
    "            new_row['Crop calendar start (month)'] = start.strip()\n",
    "            new_row['Crop calendar end (month)'] = end.strip()\n",
    "            rows.append(new_row)\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Apply the function to expand the dataset\n",
    "crop_data = expand_crop_calendar(crop_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_columns_to_remove = [\n",
    "    'Id','Crop suitability','Optimum soil moisture','temperature (C)','Humidity(%)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_data = crop_data.drop(columns=crop_columns_to_remove, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_26776\\3165805715.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  crop_data['pH'].fillna(7, inplace=True)\n",
      "C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_26776\\3165805715.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  crop_data['Irrigation required(%)'].fillna(0, inplace=True)\n",
      "C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_26776\\3165805715.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  crop_data[\"N\"].fillna(crop_data[\"N\"].min(), inplace=True)\n",
      "C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_26776\\3165805715.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  crop_data[\"P\"].fillna(crop_data[\"P\"].min(), inplace=True)\n",
      "C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_26776\\3165805715.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  crop_data[\"K\"].fillna(crop_data[\"K\"].min(), inplace=True)\n",
      "C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_26776\\3165805715.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  crop_data[\"Humidity_min\"].fillna(crop_data[\"Humidity_min\"].min(), inplace=True)\n",
      "C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_26776\\3165805715.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  crop_data[\"Temperature_min\"].fillna(crop_data[\"Temperature_min\"].min(), inplace=True)\n",
      "C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_26776\\3165805715.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  crop_data[\"Moisture_min\"].fillna(crop_data[\"Moisture_min\"].min(), inplace=True)\n",
      "C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_26776\\3165805715.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  crop_data[\"Humidity_max\"].fillna(crop_data[\"Humidity_max\"].max(), inplace=True)\n",
      "C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_26776\\3165805715.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  crop_data[\"Temperature_max\"].fillna(crop_data[\"Temperature_max\"].max(), inplace=True)\n",
      "C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_26776\\3165805715.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  crop_data[\"Moisture_max\"].fillna(crop_data[\"Moisture_max\"].max(), inplace=True)\n",
      "C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_26776\\3165805715.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  crop_data[\"Altitude (masl)\"].fillna(crop_data[\"Altitude (masl)\"].mean(), inplace=True)\n",
      "C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_26776\\3165805715.py:39: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  crop_data[\"Annual rainfall (mm)\"].fillna(crop_data[\"Annual rainfall (mm)\"].mean(), inplace=True)\n",
      "C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_26776\\3165805715.py:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  crop_data[\"Crop water need (mm/total growing period)\"].fillna(0, inplace=True)\n",
      "C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_26776\\3165805715.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  crop_data[\"Growing period (days)\"].fillna(0, inplace=True)\n",
      "C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_26776\\3165805715.py:44: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  crop_data[\"Soil type\"].fillna('Loam', inplace=True)\n",
      "C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_26776\\3165805715.py:45: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  crop_data[\"Crop type\"].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_26776\\3165805715.py:46: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  crop_data[\"Crop\"].fillna('Unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "crop_data['pH'].fillna(7, inplace=True)\n",
    "crop_data['Irrigation required(%)'].fillna(0, inplace=True)\n",
    "\n",
    "# Sample function to convert range strings into their averages\n",
    "def convert_range_to_average(value):\n",
    "    if isinstance(value, str) and '-' in value:\n",
    "        # Split the range and convert to float\n",
    "        low, high = value.split('-')\n",
    "        return (float(low) + float(high)) / 2\n",
    "    else:\n",
    "        # Return the value as is (converting to float if it's numeric)\n",
    "        try:\n",
    "            return float(value)\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "\n",
    "# Apply this function to the N, P, and K columns\n",
    "crop_data['N'] = crop_data['N'].apply(convert_range_to_average)\n",
    "crop_data['P'] = crop_data['P'].apply(convert_range_to_average)\n",
    "crop_data['K'] = crop_data['K'].apply(convert_range_to_average)\n",
    "\n",
    "\n",
    "crop_data[\"N\"].fillna(crop_data[\"N\"].min(), inplace=True)\n",
    "crop_data[\"P\"].fillna(crop_data[\"P\"].min(), inplace=True)\n",
    "crop_data[\"K\"].fillna(crop_data[\"K\"].min(), inplace=True)\n",
    "\n",
    "# Fill NaN values for min columns with their respective minimum values\n",
    "crop_data[\"Humidity_min\"].fillna(crop_data[\"Humidity_min\"].min(), inplace=True)\n",
    "crop_data[\"Temperature_min\"].fillna(crop_data[\"Temperature_min\"].min(), inplace=True)\n",
    "crop_data[\"Moisture_min\"].fillna(crop_data[\"Moisture_min\"].min(), inplace=True)\n",
    "\n",
    "# Fill NaN values for max columns with their respective maximum values\n",
    "crop_data[\"Humidity_max\"].fillna(crop_data[\"Humidity_max\"].max(), inplace=True)\n",
    "crop_data[\"Temperature_max\"].fillna(crop_data[\"Temperature_max\"].max(), inplace=True)\n",
    "crop_data[\"Moisture_max\"].fillna(crop_data[\"Moisture_max\"].max(), inplace=True)\n",
    "\n",
    "# Fill NaN values for Altitude and Annual Rainfall with their mean values\n",
    "crop_data[\"Altitude (masl)\"].fillna(crop_data[\"Altitude (masl)\"].mean(), inplace=True)\n",
    "crop_data[\"Annual rainfall (mm)\"].fillna(crop_data[\"Annual rainfall (mm)\"].mean(), inplace=True)\n",
    "\n",
    "crop_data[\"Crop water need (mm/total growing period)\"].fillna(0, inplace=True)\n",
    "crop_data[\"Growing period (days)\"].fillna(0, inplace=True)\n",
    "\n",
    "crop_data[\"Soil type\"].fillna('Loam', inplace=True)\n",
    "crop_data[\"Crop type\"].fillna('Unknown', inplace=True)\n",
    "crop_data[\"Crop\"].fillna('Unknown', inplace=True)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning test_data\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sectors_per_district = test_data['District'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning function to split potassium range into min and max\n",
    "test_data[['potassium_min', 'potassium_max']] = test_data['Potassium(ppm)'].apply(clean_potassium_range).apply(pd.Series)\n",
    "\n",
    "# Ensure the min and max columns are float type\n",
    "test_data['potassium_min'] = test_data['potassium_min'].astype(float)\n",
    "test_data['potassium_max'] = test_data['potassium_max'].astype(float)\n",
    "\n",
    "\n",
    "# Apply cleaning function to split pH range into min and max\n",
    "test_data[['phosphorus_min', 'phosphorus_max']] = test_data['Phosphorous(ppm)'].apply(clean_phosphorus_range).apply(pd.Series)\n",
    "\n",
    "# Ensure the min and max columns are float type\n",
    "test_data['phosphorus_min'] = test_data['phosphorus_min'].astype(float)\n",
    "test_data['phosphorus_max'] = test_data['phosphorus_max'].astype(float)\n",
    "\n",
    "\n",
    "# Apply cleaning function to split Phosphorous range into min and max\n",
    "test_data[['pH_min', 'pH_max']] = test_data['pH'].apply(clean_pH_range).apply(pd.Series)\n",
    "\n",
    "# Ensure the min and max columns are float type\n",
    "test_data['pH_min'] = test_data['pH_min'].astype(float)\n",
    "test_data['pH_max'] = test_data['pH_max'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = [\n",
    "    'Id','Crop suitability', 'Acid Saturation(%)', 'AcidSat', 'Boron (ppm)', 'Calcium(%)', \n",
    "    'Calcium(ppm)', 'Copper (ppm)', 'Magnessium(%)', 'Magnessium(ppm)', \n",
    "    'Manganese(ppm)', 'Manganese', 'Organic Matter(%)', 'Phosphorous(ppm)', \n",
    "    'Potassium (%)', 'Potassium(ppm)', 'Sulphur (ppm)', 'Zinc (ppm)', 'temperature (C)', 'pH', 'Optimum soil moisture', 'Humidity(%)'\n",
    "]\n",
    "\n",
    "test_data = test_data.drop(columns=columns_to_remove, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning region data\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning function to split Phosphorous range into min and max\n",
    "region_data[['pH_min', 'pH_max']] = region_data['PH'].apply(clean_pH_range).apply(pd.Series)\n",
    "\n",
    "# Ensure the min and max columns are float type\n",
    "region_data['pH_min'] = region_data['pH_min'].astype(float)\n",
    "region_data['pH_max'] = region_data['pH_max'].astype(float)\n",
    "\n",
    "region_data.drop(columns=['PH'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalized function to clean any suitability column\n",
    "def clean_suitability(value):\n",
    "    # Standardize the suitability level\n",
    "    if \"High\" in value:\n",
    "        suitability = \"High\"\n",
    "    elif \"Moderate\" in value:\n",
    "        suitability = \"Moderate\"\n",
    "    elif \"Marginal\" in value:\n",
    "        suitability = \"Marginal\"\n",
    "    elif \"Unsuitable\" in value:\n",
    "        suitability = \"Unsuitable\"\n",
    "    else:\n",
    "        suitability = value\n",
    "\n",
    "    # Extract limitations\n",
    "    limitation = \"\"\n",
    "    if \"Limitation:\" in value:\n",
    "        parts = value.split(\"Limitation:\")\n",
    "        limitation = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "    \n",
    "    return pd.Series([suitability, limitation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column list\n",
    "suitability_columns = [\n",
    "    'Banana Suitability', 'Beans Suitability', 'Cassava Suitability', \n",
    "    'Maize Suitability', 'Groundnut Suitability', 'Potatoes Suitability', \n",
    "    'Sorghum Suitability', 'Peas Suitability', 'Soyabeans Suitability', \n",
    "    'Tea Suitability'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each column to apply the cleaning and create new columns\n",
    "for column in suitability_columns:\n",
    "    # Generate standardized column names without spaces and avoid trailing underscores\n",
    "    base_name = column.replace(\" \", \"_\").replace(\"Suitability\", \"\").rstrip(\"_\")  # Remove trailing underscore if exists\n",
    "    suitability_col = f\"{base_name}_Suitability\"\n",
    "    limitation_col = f\"{base_name}_Limitation\"\n",
    "    \n",
    "    # Apply cleaning function and create new columns\n",
    "    region_data[[suitability_col, limitation_col]] = region_data[column].apply(clean_suitability)\n",
    "    \n",
    "    # Optionally, drop the original column\n",
    "    region_data.drop(columns=[column], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of temperature and precipitation columns by month\n",
    "temperature_columns = [\n",
    "    'Average Temperature (°C) - Jan', 'Average Temperature (°C) - Feb', \n",
    "    'Average Temperature (°C) - Mar', 'Average Temperature (°C) - Apr',\n",
    "    'Average Temperature (°C) - May', 'Average Temperature (°C) - Jun', \n",
    "    'Average Temperature (°C) - Jul', 'Average Temperature (°C) - Aug', \n",
    "    'Average Temperature (°C) - Sep', 'Average Temperature (°C) - Oct', \n",
    "    'Average Temperature (°C) - Nov', 'Average Temperature (°C) - Dec'\n",
    "]\n",
    "\n",
    "precipitation_columns = [\n",
    "    'Average Precipitation (mm) - Jan', 'Average Precipitation (mm) - Feb', \n",
    "    'Average Precipitation (mm) - Mar', 'Average Precipitation (mm) - Apr', \n",
    "    'Average Precipitation (mm) - May', 'Average Precipitation (mm) - Jun', \n",
    "    'Average Precipitation (mm) - Jul', 'Average Precipitation (mm) - Aug', \n",
    "    'Average Precipitation (mm) - Sep', 'Average Precipitation (mm) - Oct', \n",
    "    'Average Precipitation (mm) - Nov', 'Average Precipitation (mm) - Dec'\n",
    "]\n",
    "\n",
    "# Option 1: Fill NaNs with the mean for each column\n",
    "region_data[temperature_columns] = region_data[temperature_columns].fillna(region_data[temperature_columns].mean())\n",
    "region_data[precipitation_columns] = region_data[precipitation_columns].fillna(region_data[precipitation_columns].mean())\n",
    "\n",
    "# Option 2: Fill NaNs with a fixed value (e.g., -1)\n",
    "region_data[temperature_columns] = region_data[temperature_columns].fillna(-1)\n",
    "region_data[precipitation_columns] = region_data[precipitation_columns].fillna(-1)\n",
    "\n",
    "# Option 3: Interpolate NaNs in temperature and precipitation columns\n",
    "region_data[temperature_columns] = region_data[temperature_columns].interpolate(method='linear', limit_direction='forward', axis=0)\n",
    "region_data[precipitation_columns] = region_data[precipitation_columns].interpolate(method='linear', limit_direction='forward', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of pH columns\n",
    "ph_columns = ['pH_min', 'pH_max']\n",
    "\n",
    "# Option 1: Fill NaNs with the mean for each pH column\n",
    "region_data[ph_columns] = region_data[ph_columns].fillna(region_data[ph_columns].mean())\n",
    "\n",
    "# Option 2: Fill NaNs with a specific value (e.g., -1)\n",
    "region_data[ph_columns] = region_data[ph_columns].fillna(-1)\n",
    "\n",
    "# Option 3: Interpolate NaNs in pH columns\n",
    "region_data[ph_columns] = region_data[ph_columns].interpolate(method='linear', limit_direction='forward', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = region_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the target columns containing suitability information\n",
    "target_columns = data[['Potatoes_Suitability', 'Sorghum_Suitability', 'Peas_Suitability', 'Soyabeans_Suitability', 'Tea_Suitability']]\n",
    "\n",
    "# Reshape the data into long format and remove the '_Suitability' suffix\n",
    "target_columns = target_columns.melt(var_name='Crop', value_name='Suitability')\n",
    "\n",
    "# Remove '_Suitability' from crop names to get clean crop names\n",
    "target_columns['Crop'] = target_columns['Crop'].str.replace('_Suitability', '', regex=False)\n",
    "\n",
    "# Repeat the data to match the reshaped target\n",
    "data_repeated = data.loc[data.index.repeat(len(target_columns['Crop'].unique()))].reset_index(drop=True)\n",
    "\n",
    "# Reset the index for target_columns to ensure they align\n",
    "target_columns_reset = target_columns.reset_index(drop=True)\n",
    "\n",
    "# Combine the repeated data with the reshaped target columns to form the final dataset\n",
    "cleaned_data = pd.concat([data_repeated, target_columns_reset['Crop'], target_columns_reset['Suitability']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the averages from the 12 months in cleaned_data\n",
    "cleaned_data['Average Temperature (°C)'] = cleaned_data[\n",
    "    [f'Average Temperature (°C) - {month}' for month in ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                                                         'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']]\n",
    "].mean(axis=1)\n",
    "\n",
    "cleaned_data['Average Precipitation (mm)'] = cleaned_data[\n",
    "    [f'Average Precipitation (mm) - {month}' for month in ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                                                           'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']]\n",
    "].mean(axis=1)\n",
    "\n",
    "# Step 2: Extract the features and target for training\n",
    "X_train = cleaned_data[['pH_min', 'pH_max', 'Average Temperature (°C)', 'Average Precipitation (mm)']]\n",
    "y_train = cleaned_data['Crop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Standardize the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Step 4: Train the models using the entire training data\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest.fit(X_train_scaled, y_train)\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 5: Calculate the average temperature and precipitation for test data\n",
    "if 'Temperature' in test_data.columns and 'Rainfall' in test_data.columns:\n",
    "    test_data['Average Temperature (°C)'] = test_data['Temperature']\n",
    "    test_data['Average Precipitation (mm)'] = test_data['Rainfall']\n",
    "\n",
    "# Step 6: Prepare the test data with matching features\n",
    "X_test = test_data[['pH_min', 'pH_max', 'Average Temperature (°C)', 'Average Precipitation (mm)']]\n",
    "\n",
    "# Step 7: Standardize the test data using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 8: Make predictions using the trained models\n",
    "rf_predictions = random_forest.predict(X_test_scaled)\n",
    "dt_predictions = decision_tree.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_test: (2080, 4)\n",
      "Shape of y_test: (2080,)\n",
      "Random Forest Accuracy on test data: 0.2048076923076923\n",
      "Decision Tree Accuracy on test data: 0.2\n",
      "\n",
      "Random Forest Classification Report on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Peas       0.00      0.00      0.00       416\n",
      "    Potatoes       0.00      0.00      0.00       416\n",
      "     Sorghum       0.00      0.00      0.00       416\n",
      "   Soyabeans       0.10      0.02      0.04       416\n",
      "         Tea       0.21      1.00      0.35       416\n",
      "\n",
      "    accuracy                           0.20      2080\n",
      "   macro avg       0.06      0.20      0.08      2080\n",
      "weighted avg       0.06      0.20      0.08      2080\n",
      "\n",
      "\n",
      "Decision Tree Classification Report on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Peas       0.00      0.00      0.00       416\n",
      "    Potatoes       0.00      0.00      0.00       416\n",
      "     Sorghum       0.00      0.00      0.00       416\n",
      "   Soyabeans       0.00      0.00      0.00       416\n",
      "         Tea       0.20      1.00      0.33       416\n",
      "\n",
      "    accuracy                           0.20      2080\n",
      "   macro avg       0.04      0.20      0.07      2080\n",
      "weighted avg       0.04      0.20      0.07      2080\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\robot\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\robot\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\robot\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\robot\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\robot\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\robot\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Retrieve actual crops from region_data based on location matching\n",
    "test_data_with_crop = test_data.merge(cleaned_data[['Latitude', 'Longitude', 'Crop']], \n",
    "                                      on=['Latitude', 'Longitude'], how='left')\n",
    "\n",
    "# Make sure that 'Crop' is not NaN, or handle missing values as needed (e.g., drop rows or fill with a default value)\n",
    "test_data_with_crop = test_data_with_crop.dropna(subset=['Crop'])\n",
    "\n",
    "# Now, y_test will have the correct length\n",
    "y_test = test_data_with_crop['Crop']\n",
    "\n",
    "# Ensure X_test matches the number of samples in y_test\n",
    "X_test = test_data_with_crop[['pH_min', 'pH_max', 'Average Temperature (°C)', 'Average Precipitation (mm)']]\n",
    "\n",
    "# Check the shapes to confirm they match\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")\n",
    "\n",
    "# Standardize the test data using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 10: Make predictions using the trained models\n",
    "rf_predictions = random_forest.predict(X_test_scaled)\n",
    "dt_predictions = decision_tree.predict(X_test_scaled)\n",
    "\n",
    "# Step 11: Evaluate the models using the actual crop data from region_data\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "\n",
    "print(\"Random Forest Accuracy on test data:\", rf_accuracy)\n",
    "print(\"Decision Tree Accuracy on test data:\", dt_accuracy)\n",
    "\n",
    "print(\"\\nRandom Forest Classification Report on test data:\")\n",
    "print(classification_report(y_test, rf_predictions))\n",
    "\n",
    "print(\"\\nDecision Tree Classification Report on test data:\")\n",
    "print(classification_report(y_test, dt_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to process user input and predict the crop\n",
    "# def predict_crop(district, sector, month, cleaned_data, model='random_forest'):\n",
    "#     # Retrieve the necessary rows based on District and Sector\n",
    "#     region_data = cleaned_data[(cleaned_data['District'] == district) & (cleaned_data['Sector'] == sector)]\n",
    "    \n",
    "#     if region_data.empty:\n",
    "#         raise ValueError(f\"No data available for the given District: {district} and Sector: {sector}\")\n",
    "    \n",
    "#     # Select the relevant features\n",
    "#     features = ['Longitude', 'Latitude', 'Elevation', 'pH_min', 'pH_max'] + \\\n",
    "#                [f'Average Temperature (°C) - {m}' for m in ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "#                                                             'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']] + \\\n",
    "#                [f'Average Precipitation (mm) - {m}' for m in ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "#                                                                 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']]\n",
    "    \n",
    "#     # Define the month names list\n",
    "#     month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    \n",
    "#     # Filter the columns based on selected month\n",
    "#     month_index = month_names.index(month)\n",
    "    \n",
    "#     # Extract the relevant temperature and precipitation columns for the month\n",
    "#     temp_col = f'Average Temperature (°C) - {month_names[month_index]}'\n",
    "#     precip_col = f'Average Precipitation (mm) - {month_names[month_index]}'\n",
    "\n",
    "#     # Filter the necessary values for temperature and precipitation of the given month\n",
    "#     user_input_data = region_data[features + [temp_col, precip_col, 'Crop']]\n",
    "\n",
    "#     # Make sure that the data for the given month exists\n",
    "#     if user_input_data.empty:\n",
    "#         raise ValueError(f\"No data available for {month} in the selected region\")\n",
    "    \n",
    "#     # Prepare the input for prediction (drop 'Crop' for prediction purposes)\n",
    "#     X_user_input = user_input_data.drop(columns='Crop')  # Drop the target variable\n",
    "#     X_scaled = scaler.transform(X_user_input)  # Standardize based on the previous scaling\n",
    "\n",
    "#     # Predict with the selected model\n",
    "#     if model == 'random_forest':\n",
    "#         prediction = random_forest.predict(X_scaled)\n",
    "#     elif model == 'decision_tree':\n",
    "#         prediction = decision_tree.predict(X_scaled)\n",
    "#     else:\n",
    "#         raise ValueError(\"Invalid model selected. Choose either 'random_forest' or 'decision_tree'.\")\n",
    "\n",
    "#     return prediction[0]  # Return the predicted crop\n",
    "\n",
    "# # Example usage:\n",
    "# district_input = 'Karongi'\n",
    "# sector_input = 'Bwishyura'\n",
    "# month_input = 'Jan'\n",
    "\n",
    "# # Predict the crop based on the user input\n",
    "# predicted_crop = predict_crop(district_input, sector_input, month_input, cleaned_data, model='random_forest')\n",
    "# print(f\"Predicted Crop: {predicted_crop}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# label_encoders = {}\n",
    "# for column in ['District', 'Sector']:\n",
    "#     le = LabelEncoder()\n",
    "#     X[column] = le.fit_transform(X[column])\n",
    "#     label_encoders[column] = le\n",
    "\n",
    "# # Standardize features (especially the temperature and precipitation values)\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preprocess the dataset\n",
    "# data = data.dropna()  # Remove rows with missing values\n",
    "\n",
    "# # Encode categorical variables\n",
    "# label_encoders = {}\n",
    "# for column in ['District', 'Sector']:  # Add any other categorical columns as needed\n",
    "#     le = LabelEncoder()\n",
    "#     data[column] = le.fit_transform(data[column])\n",
    "#     label_encoders[column] = le\n",
    "\n",
    "# # Calculate mean temperature and precipitation for each month\n",
    "# data['Avg_Temperature'] = data[[f'Average Temperature (°C) - {month}' for month in \n",
    "#                                 ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']]].mean(axis=1)\n",
    "# data['Avg_Precipitation'] = data[[f'Average Precipitation (mm) - {month}' for month in \n",
    "#                                   ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']]].mean(axis=1)\n",
    "\n",
    "# # Define input variables (X)\n",
    "# X = data[['Elevation', 'pH_min', 'pH_max', 'Avg_Temperature', 'Avg_Precipitation']]\n",
    "\n",
    "# # Reshape the target variable (y) into a long format with 'Crop' and 'Suitability'\n",
    "# y = data[['Potatoes_Suitability', 'Sorghum_Suitability', 'Peas_Suitability', 'Soyabeans_Suitability', 'Tea_Suitability']]\n",
    "# y = y.melt(var_name='Crop', value_name='Suitability') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features for better model performance\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Initialize models\n",
    "# rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# # Train models\n",
    "# rf_model.fit(X_train, y_train['Suitability'])\n",
    "# dt_model.fit(X_train, y_train['Suitability'])\n",
    "\n",
    "# # Predict using the models\n",
    "# rf_predictions = rf_model.predict(X_test)\n",
    "# dt_predictions = dt_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the models\n",
    "# # Calculate accuracy\n",
    "# rf_accuracy = accuracy_score(y_test['Suitability'], rf_predictions)\n",
    "# dt_accuracy = accuracy_score(y_test['Suitability'], dt_predictions)\n",
    "\n",
    "# # Detailed classification report for each model\n",
    "# print(\"Random Forest Classification Report:\")\n",
    "# print(classification_report(y_test['Suitability'], rf_predictions))\n",
    "\n",
    "# print(\"\\nDecision Tree Classification Report:\")\n",
    "# print(classification_report(y_test['Suitability'], dt_predictions))\n",
    "\n",
    "# # Print accuracies\n",
    "# print(f'\\nRandom Forest Accuracy: {rf_accuracy:.2f}')\n",
    "# print(f'Decision Tree Accuracy: {dt_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preprocess the dataset\n",
    "# data = data.dropna()  # Remove rows with missing values\n",
    "\n",
    "# # Encode categorical variables\n",
    "# label_encoders = {}\n",
    "# for column in ['District', 'Sector']:  # Add any other categorical columns as needed\n",
    "#     le = LabelEncoder()\n",
    "#     data[column] = le.fit_transform(data[column])\n",
    "#     label_encoders[column] = le\n",
    "\n",
    "# # Define input and target variables\n",
    "# # # Add temperature and precipitation columns for each month to X\n",
    "# # X = data[['Elevation', 'pH_min', 'pH_max'] +\n",
    "# #          [f'Average Temperature (°C) - {month}' for month in ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "# #                                                               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']] +\n",
    "# #          [f'Average Precipitation (mm) - {month}' for month in ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "# #                                                                 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']]]\n",
    "# # y = data[['Potatoes_Suitability', 'Sorghum_Suitability', 'Peas_Suitability', 'Soyabeans_Suitability', 'Tea_Suitability']]\n",
    "# # Calculate mean temperature and precipitation for each month\n",
    "# data['Avg_Temperature'] = data[[f'Average Temperature (°C) - {month}' for month in \n",
    "#                                 ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']]].mean(axis=1)\n",
    "# data['Avg_Precipitation'] = data[[f'Average Precipitation (mm) - {month}' for month in \n",
    "#                                   ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']]].mean(axis=1)\n",
    "\n",
    "# # Define input and target variables\n",
    "# X = data[['Elevation', 'pH_min', 'pH_max', 'Avg_Temperature', 'Avg_Precipitation']]\n",
    "# y = data[['Potatoes_Suitability', 'Sorghum_Suitability', 'Peas_Suitability', 'Soyabeans_Suitability', 'Tea_Suitability']]\n",
    "\n",
    "# # Standardize features for better model performance\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # Split the dataset\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Initialize models\n",
    "# rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# # Train models\n",
    "# rf_model.fit(X_train, y_train)\n",
    "# dt_model.fit(X_train, y_train)\n",
    "\n",
    "# # Predict using the models\n",
    "# rf_predictions = rf_model.predict(X_test)\n",
    "# dt_predictions = dt_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the models\n",
    "# # Calculate accuracy for each target separately\n",
    "# rf_accuracies = [accuracy_score(y_test.iloc[:, i], rf_predictions[:, i]) for i in range(y_test.shape[1])]\n",
    "# dt_accuracies = [accuracy_score(y_test.iloc[:, i], dt_predictions[:, i]) for i in range(y_test.shape[1])]\n",
    "\n",
    "# # Average accuracy across all targets\n",
    "# rf_average_accuracy = sum(rf_accuracies) / len(rf_accuracies)\n",
    "# dt_average_accuracy = sum(dt_accuracies) / len(dt_accuracies)\n",
    "\n",
    "# # Detailed classification report for each model and target\n",
    "# print(\"Random Forest Classification Report:\")\n",
    "# for i, target in enumerate(y.columns):\n",
    "#     print(f\"\\nTarget: {target}\")\n",
    "#     print(classification_report(y_test.iloc[:, i], rf_predictions[:, i]))\n",
    "\n",
    "# print(\"\\nDecision Tree Classification Report:\")\n",
    "# for i, target in enumerate(y.columns):\n",
    "#     print(f\"\\nTarget: {target}\")\n",
    "#     print(classification_report(y_test.iloc[:, i], dt_predictions[:, i]))\n",
    "\n",
    "# # Print average accuracies\n",
    "# print(f'\\nRandom Forest Average Accuracy: {rf_average_accuracy:.2f}')\n",
    "# print(f'Decision Tree Average Accuracy: {dt_average_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Encode district and sector\n",
    "# district_encoded = label_encoders['District'].transform([\"Karongi\"])[0]\n",
    "# sector_encoded = label_encoders['Sector'].transform([\"Bwishyura\"])[0]\n",
    "    \n",
    "#     # Set default values for other features (average values from dataset)\n",
    "# elevation_avg = X['Elevation'].mean()\n",
    "# ph_min_avg = X['pH_min'].mean()\n",
    "# ph_max_avg = X['pH_max'].mean()\n",
    "# avg_temp = X['Avg_Temperature'].mean()\n",
    "# avg_precip = X['Avg_Precipitation'].mean()\n",
    "    \n",
    "#     # Combine all values into a single input vector with consistent column names\n",
    "# input_data = pd.DataFrame([[elevation_avg, ph_min_avg, ph_max_avg, avg_temp, avg_precip]], \n",
    "#                               columns=['Elevation', 'pH_min', 'pH_max', 'Avg_Temperature', 'Avg_Precipitation'])\n",
    "    \n",
    "#     # Scale the input data using StandardScaler\n",
    "# input_data = scaler.transform(input_data)\n",
    "    \n",
    "#     # Predict suitability for each crop using Random Forest model\n",
    "# rf_prediction = rf_model.predict(input_data)\n",
    "# dt_prediction = dt_model.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prediction function for new user inputs\n",
    "# def predict_crop_suitability(district, sector):\n",
    "#     # Encode district and sector\n",
    "#     district_encoded = label_encoders['District'].transform([district])[0]\n",
    "#     sector_encoded = label_encoders['Sector'].transform([sector])[0]\n",
    "    \n",
    "#     # Set default values for other features (average values from dataset)\n",
    "#     elevation_avg = X['Elevation'].mean()\n",
    "#     ph_min_avg = X['pH_min'].mean()\n",
    "#     ph_max_avg = X['pH_max'].mean()\n",
    "#     avg_temp = X['Avg_Temperature'].mean()\n",
    "#     avg_precip = X['Avg_Precipitation'].mean()\n",
    "    \n",
    "#     # Combine all values into a single input vector with consistent column names\n",
    "#     input_data = pd.DataFrame([[elevation_avg, ph_min_avg, ph_max_avg, avg_temp, avg_precip]], \n",
    "#                               columns=['Elevation', 'pH_min', 'pH_max', 'Avg_Temperature', 'Avg_Precipitation'])\n",
    "    \n",
    "#     # Scale the input data using StandardScaler\n",
    "#     input_data = scaler.transform(input_data)\n",
    "    \n",
    "#     # Predict suitability for each crop using Random Forest model\n",
    "#     rf_prediction = rf_model.predict(input_data)\n",
    "#     dt_prediction = dt_model.predict(input_data)\n",
    "    \n",
    "#     # Return predictions from both models\n",
    "#     return {\n",
    "#         rf_prediction\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example prediction\n",
    "# district_input = \"Kirehe\"  # Replace with actual district\n",
    "# sector_input = \"Musaza\"      # Replace with actual sector\n",
    "# predictions = predict_crop_suitability(district_input, sector_input)\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_districts = region_data['District'].unique()\n",
    "# print(\"Unique Districts in DataFrame:\", unique_districts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoders['District'] = LabelEncoder()\n",
    "# label_encoders['Sector'] = LabelEncoder()\n",
    "# label_encoders['District'].fit(region_data['District']) \n",
    "# label_encoders['Sector'].fit(region_data['Sector']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def recommend_crops(district, sector):\n",
    "#     # Normalize the input\n",
    "#     district = district.strip()\n",
    "#     sector = sector.strip()\n",
    "\n",
    "#     # Check if the input district and sector are valid\n",
    "#     if district not in label_encoders['District'].classes_:\n",
    "#         raise ValueError(f\"District '{district}' not recognized. Please check the input.\")\n",
    "    \n",
    "#     if sector not in label_encoders['Sector'].classes_:\n",
    "#         raise ValueError(f\"Sector '{sector}' not recognized. Please check the input.\")\n",
    "    \n",
    "#     # Encode user input\n",
    "#     district_encoded = label_encoders['District'].transform([district])[0]\n",
    "#     sector_encoded = label_encoders['Sector'].transform([sector])[0]\n",
    "    \n",
    "#     # Prepare input for prediction\n",
    "#     user_input = pd.DataFrame({\n",
    "#         'District': [district_encoded],\n",
    "#         'Sector': [sector_encoded]\n",
    "#     })\n",
    "\n",
    "#     # Collect probabilities for each crop target\n",
    "#     crop_names = ['Potatoes', 'Sorghum', 'Peas', 'Soyabeans', 'Tea']\n",
    "#     rf_probabilities = []\n",
    "\n",
    "#     for i in range(len(crop_names)):\n",
    "#         crop_probs = rf_model.estimators_[i].predict_proba(user_input)[0]  # Get probabilities for each crop\n",
    "#         rf_probabilities.append(crop_probs)\n",
    "\n",
    "#     # Convert list of lists into a DataFrame\n",
    "#     rf_probabilities = pd.DataFrame(rf_probabilities, index=crop_names)\n",
    "\n",
    "#     # Ensure rf_probabilities has the expected structure\n",
    "#     if rf_probabilities.shape[1] != 5:\n",
    "#         raise ValueError(\"Unexpected structure of rf_probabilities. Verify model output.\")\n",
    "\n",
    "#     # Mean and top crop recommendations\n",
    "#     top_crops = rf_probabilities.mean(axis=1).nlargest(5)\n",
    "    \n",
    "#     return top_crops\n",
    "\n",
    "# # Example usage\n",
    "# try:\n",
    "#     recommended_crops = recommend_crops('Nyarugenge', 'Gitega')\n",
    "#     print(recommended_crops)\n",
    "# except ValueError as e:\n",
    "#     print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
