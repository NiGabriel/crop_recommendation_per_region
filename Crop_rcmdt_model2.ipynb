{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "id": "mg2Iji4iZXe9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import joblib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "id": "0yP_5YLaa8ZJ"
   },
   "outputs": [],
   "source": [
    "# crop_data = pd.read_excel('/content/drive/MyDrive/model dvpt data/crop_recommendation.xlsx', sheet_name=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "id": "m-6QrBkja8Ht"
   },
   "outputs": [],
   "source": [
    "crop_data = pd.read_csv('dataset/filtered_sampled_dataset.csv')\n",
    "region_data = pd.read_excel('dataset/crop_recommendations.xlsx', sheet_name=2)\n",
    "\n",
    "# crop_data = pd.read_excel('dataset/crop_recommendations.xlsx', sheet_name=0)\n",
    "# crop_data = pd.read_excel('/content/drive/MyDrive/model dvpt data/crop_recommendation2.xlsx', sheet_name=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "id": "8czVMMVpePkX"
   },
   "outputs": [],
   "source": [
    "# # Function to sample a value from a range or threshold\n",
    "# def sample_from_range(value):\n",
    "#     # Remove commas from numbers\n",
    "#     if isinstance(value, str):\n",
    "#         value = value.replace(',', '')\n",
    "\n",
    "#     # Check if the value is a range (e.g., '45-60')\n",
    "#     if isinstance(value, str) and '-' in value:\n",
    "#         parts = value.split('-')\n",
    "#         if len(parts) == 2 and all(part.strip().replace('.', '', 1).isdigit() for part in parts):\n",
    "#             low, high = map(float, parts)\n",
    "#             return np.random.uniform(low, high)\n",
    "\n",
    "#     # Check for '>' or '<' in the value, e.g., '>60' or '<45'\n",
    "#     if isinstance(value, str) and value:\n",
    "#         if value[0] == '>':\n",
    "#             threshold = float(value[1:].strip())\n",
    "#             return np.random.uniform(threshold, threshold + 20)  # Sample within a range above the threshold\n",
    "#         elif value[0] == '<':\n",
    "#             threshold = float(value[1:].strip())\n",
    "#             return np.random.uniform(threshold - 20, threshold)  # Sample within a range below the threshold\n",
    "\n",
    "#     # Check for symbol at the end (e.g., '50<')\n",
    "#     if isinstance(value, str) and value[-1] == '<':\n",
    "#         threshold = float(value[:-1].strip())  # Remove the '<' symbol and convert to float\n",
    "#         return np.random.uniform(threshold - 20, threshold)  # Sample within a range below the threshold\n",
    "\n",
    "#     # Check if the value is a valid number after removing commas\n",
    "#     if isinstance(value, str) and value.replace('.', '', 1).isdigit():\n",
    "#         return float(value)  # Return as float after removing commas\n",
    "\n",
    "#     return value\n",
    "\n",
    "# # Function to generate samples for each crop\n",
    "# def generate_samples(data, num_samples=100):\n",
    "#     sampled_data = []\n",
    "#     for _, row in data.iterrows():\n",
    "#         for _ in range(num_samples):\n",
    "#             sampled_row = row.copy()\n",
    "#             sampled_row['Altitude (masl)'] = sample_from_range(row['Altitude (masl)'])\n",
    "#             sampled_row['temperature (C) '] = sample_from_range(row['temperature (C) '])\n",
    "#             sampled_row['pH'] = sample_from_range(row['pH'])\n",
    "#             sampled_row['Crop water need (mm/total growing period)'] = sample_from_range(row['Crop water need (mm/total growing period)'])\n",
    "#             sampled_row['Growing period (days)'] = sample_from_range(row['Growing period (days)'])\n",
    "#             sampled_row['Humidity(%)'] = sample_from_range(row['Humidity(%)'])\n",
    "#             sampled_row['N'] = sample_from_range(row['N'])\n",
    "#             sampled_row['P'] = sample_from_range(row['P'])\n",
    "#             sampled_row['K'] = sample_from_range(row['K'])\n",
    "#             sampled_data.append(sampled_row)\n",
    "#     return pd.DataFrame(sampled_data)\n",
    "\n",
    "# # Generate the new sampled dataset\n",
    "# sampled_dataset = generate_samples(crop_data, num_samples=100)\n",
    "sampled_dataset = crop_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "id": "xj6wF6o2var0"
   },
   "outputs": [],
   "source": [
    "crop_columns_to_remove = [\n",
    "    'Id','Crop suitability','Irrigation required(%)'\n",
    "]\n",
    "\n",
    "sampled_dataset = sampled_dataset.drop(columns=crop_columns_to_remove, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "id": "2S6Qq9DpJSRo"
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    # 'Random Forest': RandomForestClassifier(\n",
    "    #     n_estimators=100,                # Increase number of trees\n",
    "    #     max_depth=6,                    # Maximum depth of trees (limit complexity)\n",
    "    #     min_samples_split=5,             # Minimum samples required to split a node\n",
    "    #     min_samples_leaf=2,              # Minimum samples required to be at a leaf\n",
    "    #     max_features='sqrt',             # Use a subset of features (helps generalization)\n",
    "    #     bootstrap=True,                  # Use bootstrapping\n",
    "    #     class_weight='balanced',         # Adjust weights for class imbalance\n",
    "    #     random_state=42\n",
    "    # ),\n",
    "    # 'Decision Tree': DecisionTreeClassifier(\n",
    "    #     max_depth=6,                     # Limit depth to avoid overfitting\n",
    "    #     min_samples_split=6,             # Minimum samples to split a node\n",
    "    #     min_samples_leaf=3,              # Minimum samples at a leaf node\n",
    "    #     max_features='sqrt',             # Use a subset of features\n",
    "    #     criterion='entropy',             # Use 'entropy' or 'gini' for split quality\n",
    "    #     random_state=42\n",
    "    # ),\n",
    "    # 'SVM': SVC(\n",
    "    #     kernel='rbf',                    # Kernel type: 'linear', 'poly', 'rbf', 'sigmoid'\n",
    "    #     C=0.5,                           # Lower C value for regularization\n",
    "    #     gamma='scale',                   # Adjust gamma for non-linear kernels\n",
    "    #     probability=True,                # Enable probability estimates\n",
    "    #     class_weight='balanced',         # Adjust for class imbalance\n",
    "    #     random_state=42\n",
    "    # ),\n",
    "    # 'Naive Bayes': GaussianNB(\n",
    "    #     var_smoothing=1e-8        # Additive smoothing parameter\n",
    "    # ),\n",
    "    'XGBoost': XGBClassifier(\n",
    "        n_estimators=200,                # Increase number of boosting rounds\n",
    "        learning_rate=0.05,              # Lower learning rate\n",
    "        max_depth=4,                     # Decrease max depth to avoid overfitting\n",
    "        min_child_weight=3,              # Minimum sum of instance weight needed in a child\n",
    "        gamma=0.1,                       # Minimum loss reduction required to split\n",
    "        subsample=0.8,                   # Fraction of samples used for training each tree\n",
    "        colsample_bytree=0.8,            # Fraction of features used for training each tree\n",
    "        reg_lambda=1.5,                  # L2 regularization\n",
    "        reg_alpha=0.5,                   # L1 regularization (adds sparsity)\n",
    "        eval_metric='mlogloss',\n",
    "        random_state=42\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "id": "tk_vMDSqLVRF"
   },
   "outputs": [],
   "source": [
    "# Prepare the dataset for training\n",
    "train_features = sampled_dataset[['Altitude (masl)', 'temperature (C) ',\n",
    "                             'pH', 'N', 'P', 'K','Crop water need (mm/total growing period)', 'Humidity(%)']]\n",
    "target = sampled_dataset['Crop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "id": "P6B3QEzqcXpr"
   },
   "outputs": [],
   "source": [
    "# Encode the target variable to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "target_encoded = label_encoder.fit_transform(target)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_features, target_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "id": "e5H1DjfwdROn"
   },
   "outputs": [],
   "source": [
    "# Initialize model_accuracies\n",
    "model_accuracies = {name: [] for name in models.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gDYrzuCFcPwq",
    "outputId": "8295792e-80d4-493f-9de1-b6dd6169633a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost...\n",
      "\n",
      "XGBoost Accuracy: 1.0000\n",
      "\n",
      "Best Model: XGBoost with mean accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Function to train and evaluate models\n",
    "def train_and_evaluate(models, X_train, X_test, y_train, y_test):\n",
    "    results = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"Training {name}...\")\n",
    "        try:\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            print(f\"\\n{name} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "            # Calculate classification report\n",
    "            report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "            # Store results\n",
    "            results[name] = {\n",
    "                'model': model,\n",
    "                'accuracy': accuracy,\n",
    "                'classification_report': report\n",
    "            }\n",
    "\n",
    "            # Append the accuracy to the model_accuracies list\n",
    "            model_accuracies[name].append(accuracy)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error training {name}: {str(e)}\")\n",
    "            results[name] = {\n",
    "                'model': None,\n",
    "                'accuracy': None,\n",
    "                'classification_report': None,\n",
    "                'error': str(e)\n",
    "            }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Train and evaluate all models\n",
    "results = train_and_evaluate(models, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Calculate mean accuracies\n",
    "mean_accuracies = {\n",
    "    model_name: (sum(accuracies) / len(accuracies)) if len(accuracies) > 0 else 0\n",
    "    for model_name, accuracies in model_accuracies.items()\n",
    "}\n",
    "\n",
    "# Determine the best model\n",
    "best_model_name = max(mean_accuracies, key=mean_accuracies.get)\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name} with mean accuracy: {mean_accuracies[best_model_name]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "id": "UywwCNDKcagp"
   },
   "outputs": [],
   "source": [
    "# sampled_dataset.to_csv('sampled_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "id": "Y7_uO52eYOve"
   },
   "outputs": [],
   "source": [
    "# Step 1: Drop rows with specific unwanted text entries\n",
    "unwanted_text = ['Protected Land', 'Water Body']\n",
    "region_data = region_data[~region_data['pH'].isin(unwanted_text)]\n",
    "\n",
    "# Step 2: Function to calculate average pH\n",
    "def calculate_average_ph(ph_value):\n",
    "    # Handle special case for values like '<5.0'\n",
    "    if '<' in ph_value:\n",
    "        # Convert '<5.0' to 5.0 (assuming '<5.0' means \"up to 5.0\")\n",
    "        return float(ph_value.replace('<', ''))\n",
    "    elif '>' in ph_value:\n",
    "        return float(ph_value.replace('>',''))\n",
    "\n",
    "    # Handle range values like '6.0-7.0'\n",
    "    if '-' in ph_value:\n",
    "        lower, upper = map(float, ph_value.split('-'))\n",
    "        return (lower + upper) / 2\n",
    "\n",
    "    # Convert single numeric value to float\n",
    "    return float(ph_value)\n",
    "\n",
    "# Step 3: Apply the function to the 'pH' column\n",
    "region_data['pH_avg'] = region_data['pH'].apply(calculate_average_ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_crop_data(crop_names, dataset):\n",
    "    \"\"\"Fetch additional data for the predicted crops, including seasonal information.\"\"\"\n",
    "    crop_details = {}\n",
    "    for crop in crop_names:\n",
    "        crop_info = dataset[dataset['Crop'] == crop]\n",
    "        if not crop_info.empty:\n",
    "            # Extract relevant details for each crop\n",
    "            crop_details[crop] = {\n",
    "                'Season A start': crop_info['Season A start(month)'].values[0],\n",
    "                'Season A end': crop_info['Season A end'].values[0],\n",
    "                'Season B start': crop_info['Season B start(month)'].values[0],\n",
    "                'Season B end': crop_info['Season B end(month)'].values[0],\n",
    "                'Growing period (days)': crop_info['Growing period (days)'].values[0],\n",
    "            }\n",
    "    return crop_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_monthly_avg(data, start_month, end_month, col_prefix):\n",
    "    # Ensure that start_month and end_month are integers\n",
    "    start_month = int(start_month)\n",
    "    end_month = int(end_month)\n",
    "    \n",
    "    print(f\"DEBUG: start_month (after conversion) = {start_month}\")\n",
    "    print(f\"DEBUG: end_month (after conversion) = {end_month}\")\n",
    "\n",
    "    # Generate month indices based on the start and end months\n",
    "    if start_month <= end_month:\n",
    "        month_indices = list(range(start_month, end_month + 1))\n",
    "    else:  # Handle case where the period spans the year-end (e.g., Nov to Feb)\n",
    "        month_indices = list(range(start_month, 13)) + list(range(1, end_month + 1))\n",
    "    \n",
    "    print(f\"DEBUG: Generated month_indices = {month_indices}\")\n",
    "\n",
    "    # Extract relevant column names based on the month indices\n",
    "    monthly_columns = [f\"{col_prefix} - {datetime(1900, month, 1).strftime('%b')}\" for month in month_indices]\n",
    "    \n",
    "    print(f\"DEBUG: Extracted monthly_columns = {monthly_columns}\")\n",
    "\n",
    "    # Calculate the average of the selected months\n",
    "    avg_value = data[monthly_columns].mean(axis=1).values[0]\n",
    "    \n",
    "    print(f\"DEBUG: Calculated avg_value = {avg_value}\")\n",
    "    return avg_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month_avg(region_data, start_date):\n",
    "    \"\"\"Get average temperature, rainfall, and crop water need based on the month of the start date.\"\"\"\n",
    "    start_month = datetime.strptime(start_date, \"%Y-%m-%d\").month\n",
    "    print(f\"DEBUG: start_date = {start_date}, parsed start_month = {start_month}\")\n",
    "\n",
    "    # Extract the relevant columns for the selected month\n",
    "    avg_temperature = extract_monthly_avg(region_data, start_month, start_month, \"Average Temperature (°C)\")\n",
    "    avg_rainfall = extract_monthly_avg(region_data, start_month, start_month, \"Average Precipitation (mm)\")\n",
    "\n",
    "    print(f\"DEBUG: Avg temperature for month {start_month}: {avg_temperature}\")\n",
    "    print(f\"DEBUG: Avg rainfall for month {start_month}: {avg_rainfall}\")\n",
    "\n",
    "    return avg_temperature, avg_rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "id": "dGuk477Fm9yV"
   },
   "outputs": [],
   "source": [
    "# User input\n",
    "user_input = {\n",
    "    \"district\": \"Gasabo\",\n",
    "    \"sector\": \"Bumbogo\",\n",
    "    \"start_date_to_plant\": \"2024-02-01\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_best_crops(features, best_model, label_encoder, top_n=5):\n",
    "    \"\"\"Predict top crops based on input features.\"\"\"\n",
    "    features_df = pd.DataFrame([features])\n",
    "\n",
    "    print(\"\\nDEBUG: Input features for prediction:\")\n",
    "    print(features_df)\n",
    "\n",
    "    # Ensure the feature order matches the model's training data\n",
    "    feature_columns = [\n",
    "        'Altitude (masl)', 'temperature (C) ', 'pH', 'N', 'P', 'K', \n",
    "        'Crop water need (mm/total growing period)', 'Humidity(%)'\n",
    "    ]\n",
    "    features_df = features_df[feature_columns]\n",
    "    \n",
    "    # Make a prediction using the best model\n",
    "    try:\n",
    "        predictions_proba = best_model.predict_proba(features_df)[0]\n",
    "        print(\"\\nDEBUG: Prediction probabilities:\", predictions_proba)\n",
    "    except AttributeError as e:\n",
    "        print(\"\\nDEBUG: Model does not support predict_proba. Error:\", str(e))\n",
    "        predicted_class = best_model.predict(features_df)[0]\n",
    "        return [label_encoder.inverse_transform([predicted_class])[0]]\n",
    "\n",
    "    # Get the indices of the top N predictions with the highest probability\n",
    "    top_n_indices = np.argsort(predictions_proba)[-top_n:][::-1]\n",
    "\n",
    "    # Get the crop names and their corresponding probabilities\n",
    "    top_crops = label_encoder.inverse_transform(top_n_indices)\n",
    "    top_probabilities = predictions_proba[top_n_indices]\n",
    "\n",
    "    print(\"\\nDEBUG: Top crops and their probabilities:\")\n",
    "    for crop, prob in zip(top_crops, top_probabilities):\n",
    "        print(f\"Crop: {crop}, Probability: {prob}\")\n",
    "\n",
    "    # Return both top crops and their probabilities\n",
    "    return list(zip(top_crops, top_probabilities))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction and prediction\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to convert non-serializable types\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, np.int64):\n",
    "        return int(obj)  # Convert to native Python int\n",
    "    elif isinstance(obj, dict):\n",
    "        return {key: convert_to_serializable(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(item) for item in obj]\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DEBUG: Filtered region data found.\n",
      "    Longitude  Latitude  Prov_ID     Province  Dist_ID District  Sect_ID  \\\n",
      "10  30.155913  -1.88784        1  Kigali City       12   Gasabo   1201.0   \n",
      "\n",
      "     Sector Acid Saturation(%)  AcidSat  ...  \\\n",
      "10  Bumbogo                >10      NaN  ...   \n",
      "\n",
      "    Average Precipitation (mm) - Apr  Average Precipitation (mm) - May  \\\n",
      "10                             182.0                             126.0   \n",
      "\n",
      "    Average Precipitation (mm) - Jun  Average Precipitation (mm) - Jul  \\\n",
      "10                              19.0                               9.0   \n",
      "\n",
      "    Average Precipitation (mm) - Aug  Average Precipitation (mm) - Sep  \\\n",
      "10                              25.0                              66.0   \n",
      "\n",
      "    Average Precipitation (mm) - Oct  Average Precipitation (mm) - Nov  \\\n",
      "10                              97.0                             122.0   \n",
      "\n",
      "    Average Precipitation (mm) - Dec pH_avg  \n",
      "10                              93.0  5.755  \n",
      "\n",
      "[1 rows x 56 columns]\n",
      "\n",
      "DEBUG: Extracted features:\n",
      "Humidity: 75.41317507, pH: 5.755, K: 47.92388791, P: 12.46373804, N: 156.6364658, Altitude: 1741\n",
      "DEBUG: start_date = 2024-02-01, parsed start_month = 2\n",
      "DEBUG: start_month (after conversion) = 2\n",
      "DEBUG: end_month (after conversion) = 2\n",
      "DEBUG: Generated month_indices = [2]\n",
      "DEBUG: Extracted monthly_columns = ['Average Temperature (°C) - Feb']\n",
      "DEBUG: Calculated avg_value = 20.0\n",
      "DEBUG: start_month (after conversion) = 2\n",
      "DEBUG: end_month (after conversion) = 2\n",
      "DEBUG: Generated month_indices = [2]\n",
      "DEBUG: Extracted monthly_columns = ['Average Precipitation (mm) - Feb']\n",
      "DEBUG: Calculated avg_value = 95.0\n",
      "DEBUG: Avg temperature for month 2: 20.0\n",
      "DEBUG: Avg rainfall for month 2: 95.0\n",
      "\n",
      "DEBUG: Final features for prediction:\n",
      "{'Altitude (masl)': 1741, 'temperature (C) ': 20.0, 'pH': 5.755, 'N': 156.6364658, 'P': 12.46373804, 'K': 47.92388791, 'Crop water need (mm/total growing period)': 95.0, 'Humidity(%)': 75.41317507}\n",
      "\n",
      "DEBUG: Input features for prediction:\n",
      "   Altitude (masl)  temperature (C)      pH           N          P          K  \\\n",
      "0             1741              20.0  5.755  156.636466  12.463738  47.923888   \n",
      "\n",
      "   Crop water need (mm/total growing period)  Humidity(%)  \n",
      "0                                       95.0    75.413175  \n",
      "\n",
      "DEBUG: Prediction probabilities: [0.02635885 0.11100299 0.00542925 0.03420202 0.00658591 0.01545433\n",
      " 0.00536327 0.00446865 0.00620243 0.03240905 0.01723004 0.00669089\n",
      " 0.00583051 0.01472722 0.00500639 0.00755145 0.03488532 0.65542567\n",
      " 0.00517574]\n",
      "\n",
      "DEBUG: Top crops and their probabilities:\n",
      "Crop: Tomato, Probability: 0.6554256677627563\n",
      "Crop: Beans, Probability: 0.11100298911333084\n",
      "Crop: Tea, Probability: 0.03488531708717346\n",
      "Crop: Cabbage, Probability: 0.03420201689004898\n",
      "Crop: Mango, Probability: 0.03240904584527016\n",
      "\n",
      "DEBUG: Final output:\n",
      "{\n",
      "    \"predicted_crops\": [\n",
      "        {\n",
      "            \"crop_name\": \"Tomato\",\n",
      "            \"probability\": 0.6554256677627563,\n",
      "            \"Season A start\": 9,\n",
      "            \"Season A end\": \"1-3\",\n",
      "            \"Season B start\": 2,\n",
      "            \"Season B end\": \"6-8\",\n",
      "            \"Growing period (days)\": 171.50243344859098\n",
      "        },\n",
      "        {\n",
      "            \"crop_name\": \"Beans\",\n",
      "            \"probability\": 0.11100298911333084,\n",
      "            \"Season A start\": 9,\n",
      "            \"Season A end\": \"11-12\",\n",
      "            \"Season B start\": 2,\n",
      "            \"Season B end\": \"4-5\",\n",
      "            \"Growing period (days)\": 84.52859683983476\n",
      "        },\n",
      "        {\n",
      "            \"crop_name\": \"Tea\",\n",
      "            \"probability\": 0.03488531708717346,\n",
      "            \"Season A start\": 9,\n",
      "            \"Season A end\": \"9-10\",\n",
      "            \"Season B start\": 2,\n",
      "            \"Season B end\": \"2-3\",\n",
      "            \"Growing period (days)\": 1137.6061711613158\n",
      "        },\n",
      "        {\n",
      "            \"crop_name\": \"Cabbage\",\n",
      "            \"probability\": 0.03420201689004898,\n",
      "            \"Season A start\": 9,\n",
      "            \"Season A end\": \"1-2\",\n",
      "            \"Season B start\": 2,\n",
      "            \"Season B end\": \"6-7\",\n",
      "            \"Growing period (days)\": 133.3202318767988\n",
      "        },\n",
      "        {\n",
      "            \"crop_name\": \"Mango\",\n",
      "            \"probability\": 0.03240904584527016,\n",
      "            \"Season A start\": 9,\n",
      "            \"Season A end\": \"12-2\",\n",
      "            \"Season B start\": 2,\n",
      "            \"Season B end\": \"5-7\",\n",
      "            \"Growing period (days)\": 122.20707707812984\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Filter region data based on user input\n",
    "filtered_region = region_data[\n",
    "    (region_data['District'] == user_input['district']) & \n",
    "    (region_data['Sector'] == user_input['sector'])\n",
    "]\n",
    "\n",
    "# Check if filtered_region is empty\n",
    "if filtered_region.empty:\n",
    "    print(\"\\nDEBUG: No data found for the specified district and sector.\")\n",
    "else:\n",
    "    print(\"\\nDEBUG: Filtered region data found.\")\n",
    "    print(filtered_region)\n",
    "\n",
    "    # Extract relevant features from the filtered region\n",
    "    humidity = filtered_region['Humidity(%)'].values[0].item()\n",
    "    pH = filtered_region['pH_avg'].values[0].item()\n",
    "    potassium_min = filtered_region['Potassium(ppm)'].values[0].item()\n",
    "    phosphorus_min = filtered_region['Phosphorus(ppm)'].values[0].item()\n",
    "    nitrogen = filtered_region['Nitrogen(%)'].values[0].item()\n",
    "    altitude = filtered_region['Elevation'].values[0].item()\n",
    "\n",
    "    print(\"\\nDEBUG: Extracted features:\")\n",
    "    print(f\"Humidity: {humidity}, pH: {pH}, K: {potassium_min}, P: {phosphorus_min}, N: {nitrogen}, Altitude: {altitude}\")\n",
    "\n",
    "    # Calculate temperature and rainfall based on the provided start date\n",
    "    temperature, rainfall = get_month_avg(\n",
    "        filtered_region,\n",
    "        user_input['start_date_to_plant']\n",
    "    )\n",
    "\n",
    "    # Prepare the features for the model\n",
    "    features = {\n",
    "        'Altitude (masl)': altitude,\n",
    "        'temperature (C) ': temperature,\n",
    "        'pH': pH,\n",
    "        'N': nitrogen,\n",
    "        'P': phosphorus_min,\n",
    "        'K': potassium_min,\n",
    "        'Crop water need (mm/total growing period)': rainfall,\n",
    "        'Humidity(%)': humidity\n",
    "    }\n",
    "\n",
    "    print(\"\\nDEBUG: Final features for prediction:\")\n",
    "    print(features)\n",
    "\n",
    "    # Predict the top 5 crops along with their probabilities\n",
    "    top_crops = predict_best_crops(features, best_model, label_encoder)\n",
    "\n",
    "    # Extract crop names for querying additional data from the dataset\n",
    "    crop_names = [crop for crop, _ in top_crops]\n",
    "\n",
    "    # Fetch additional data for the predicted crops\n",
    "    crop_details = fetch_crop_data(crop_names, sampled_dataset)\n",
    "\n",
    "    # Format the output in JSON\n",
    "    output = {\n",
    "        \"predicted_crops\": [\n",
    "            {\n",
    "                \"crop_name\": crop,\n",
    "                \"probability\": float(probability),\n",
    "                **crop_details.get(crop, {})  # Merge details if available\n",
    "            }\n",
    "            for crop, probability in top_crops\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Print the output in JSON format\n",
    "    print(\"\\nDEBUG: Final output:\")\n",
    "    # Convert the output dictionary before serializing\n",
    "    output_serializable = convert_to_serializable(output)\n",
    "\n",
    "    # Now serialize to JSON\n",
    "    print(json.dumps(output_serializable, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_best_crops(features, best_model, label_encoder, top_n=5):\n",
    "#     # Convert features dictionary into a DataFrame for prediction\n",
    "#     features_df = pd.DataFrame([features])\n",
    "\n",
    "#     # Ensure the feature order matches what the model was trained on\n",
    "#     feature_columns = [\n",
    "#         'Altitude (masl)', 'temperature (C) ', 'pH', 'N', 'P', 'K', \n",
    "#         'Crop water need (mm/total growing period)', 'Humidity(%)'\n",
    "#     ]\n",
    "#     features_df = features_df[feature_columns]\n",
    "    \n",
    "#     # Make a prediction using the best model\n",
    "#     try:\n",
    "#         predictions_proba = best_model.predict_proba(features_df)[0]\n",
    "#     except AttributeError:\n",
    "#         # If the model doesn't support predict_proba, fall back to predict\n",
    "#         predicted_class = best_model.predict(features_df)[0]\n",
    "#         return [label_encoder.inverse_transform([predicted_class])[0]]\n",
    "\n",
    "#     # Get the indices of the top N predictions with the highest probability\n",
    "#     top_n_indices = np.argsort(predictions_proba)[-top_n:][::-1]\n",
    "\n",
    "#     # Get the crop names using the label encoder\n",
    "#     top_crops = label_encoder.inverse_transform(top_n_indices)\n",
    "    \n",
    "#     return top_crops\n",
    "\n",
    "# # List to store the results for each sector\n",
    "# results = []\n",
    "\n",
    "# # Iterate over each sector in the region data\n",
    "# for index, row in region_data.iterrows():\n",
    "#     # Extract relevant features from each row\n",
    "#     humidity = row['Humidity(%)']\n",
    "#     temperature = row['Temperature (°C)']\n",
    "#     pH = row['pH_avg']\n",
    "#     potassium_min = row['Potassium(ppm)']\n",
    "#     phosphorus_min = row['Phosphorus(ppm)']\n",
    "#     nitrogen = row['Nitrogen(%)']\n",
    "#     crop_water_need = row['Average Rainfall (mm)']\n",
    "#     altitude = row['Elevation']\n",
    "    \n",
    "#     # Prepare the features dictionary\n",
    "#     features = {\n",
    "#         'Altitude (masl)': altitude,\n",
    "#         'temperature (C) ': temperature,\n",
    "#         'pH': pH,\n",
    "#         'N': nitrogen,\n",
    "#         'P': phosphorus_min,\n",
    "#         'K': potassium_min,\n",
    "#         'Crop water need (mm/total growing period)': crop_water_need,\n",
    "#         'Humidity(%)': humidity\n",
    "#     }\n",
    "    \n",
    "#     # Predict the top 5 crops for the current sector\n",
    "#     top_crops = predict_best_crops(features, best_model, label_encoder)\n",
    "    \n",
    "#     # Store the results (District, Sector, and top 5 crops)\n",
    "#     results.append({\n",
    "#         'District': row['District'],\n",
    "#         'Sector': row['Sector'],\n",
    "#         'Top 1 Crop': top_crops[0] if len(top_crops) > 0 else None,\n",
    "#         'Top 2 Crop': top_crops[1] if len(top_crops) > 1 else None,\n",
    "#         'Top 3 Crop': top_crops[2] if len(top_crops) > 2 else None,\n",
    "#         'Top 4 Crop': top_crops[3] if len(top_crops) > 3 else None,\n",
    "#         'Top 5 Crop': top_crops[4] if len(top_crops) > 4 else None\n",
    "#     })\n",
    "\n",
    "# # Convert the results list into a DataFrame\n",
    "# results_df = pd.DataFrame(results)\n",
    "\n",
    "# # Save the DataFrame to a CSV file\n",
    "# csv_filename = 'best_crops_per_sector_DECISION_crops.csv'\n",
    "# results_df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8RRJ7TC_nBSj",
    "outputId": "15749f81-e6dc-4f62-bf1b-94f33a4e4412"
   },
   "outputs": [],
   "source": [
    "# # Filter region data based on user input\n",
    "# filtered_region = region_data[\n",
    "#     (region_data['District'] == user_input['district']) &\n",
    "#     (region_data['Sector'] == user_input['sector'])\n",
    "# ]\n",
    "\n",
    "# # Check if filtered_region is empty\n",
    "# if filtered_region.empty:\n",
    "#     print(\"No data found for the specified district and sector.\")\n",
    "# else:\n",
    "#     # Extract relevant features from filtered_region\n",
    "#     humidity = filtered_region['Humidity(%)'].values[0]\n",
    "#     temperature = filtered_region['Temperature (°C)'].values[0]\n",
    "#     pH = filtered_region['pH_avg'].values[0]\n",
    "#     potassium_min = filtered_region['Potassium(ppm)'].values[0]\n",
    "#     phosphorus_min = filtered_region['Phosphorus(ppm)'].values[0]\n",
    "#     nitrogen = filtered_region['Nitrogen(%)'].values[0]\n",
    "#     crop_water_need = filtered_region['Average Rainfall (mm)'].values[0]\n",
    "#     altitude = filtered_region['Elevation'].values[0]\n",
    "\n",
    "#     # Prepare the features for the model using user_input\n",
    "#     features = {\n",
    "#         'Altitude (masl)': altitude,\n",
    "#         'temperature (C) ': temperature,\n",
    "#         'pH': pH,\n",
    "#         'N': nitrogen,\n",
    "#         'P': phosphorus_min,\n",
    "#         'K': potassium_min,\n",
    "#         'Crop water need (mm/total growing period)': crop_water_need,\n",
    "#         'Humidity(%)': humidity\n",
    "#     }\n",
    "\n",
    "#     print(\"Extracted Features:\", features)\n",
    "\n",
    "#     # Convert features to DataFrame\n",
    "#     input_data = pd.DataFrame([features])  # Wrap in a list to create a DataFrame\n",
    "\n",
    "#     # Predict suitability for the input conditions using the best model\n",
    "#     predictions = best_model.predict(input_data)\n",
    "\n",
    "#     # Decode the predicted crop labels to their original string names\n",
    "#     predictions_decoded = label_encoder.inverse_transform(predictions)\n",
    "\n",
    "#     # Get predicted probabilities for all classes (crops)\n",
    "#     predicted_probabilities = best_model.predict_proba(input_data)\n",
    "\n",
    "#     # Decode the class names in the predicted probabilities\n",
    "#     decoded_classes = label_encoder.inverse_transform(best_model.classes_)\n",
    "\n",
    "#     # Create a DataFrame with decoded crops and their predicted probabilities\n",
    "#     crop_probabilities = pd.DataFrame(predicted_probabilities, columns=decoded_classes)\n",
    "#     crop_probabilities['Crop'] = predictions_decoded\n",
    "\n",
    "#     # Remove duplicates based on Crop and the predicted probabilities\n",
    "#     crop_probabilities = crop_probabilities.drop_duplicates(subset=['Crop'] + list(decoded_classes), keep='first')\n",
    "\n",
    "#     # Select the probabilities for the first row only\n",
    "#     first_row_probabilities = crop_probabilities.loc[0, decoded_classes]\n",
    "\n",
    "#     # Ensure the series is numeric and call nlargest\n",
    "#     first_row_probabilities = pd.to_numeric(first_row_probabilities, errors='coerce')\n",
    "\n",
    "#     # Get the top crops based on predicted probabilities\n",
    "#     top_crops = first_row_probabilities.nlargest(5).reset_index()\n",
    "#     top_crops.columns = ['Crop', 'Probability']\n",
    "\n",
    "#     # Decode the crop names\n",
    "#     top_crops['Crop'] = top_crops['Crop'].astype(str)\n",
    "#     crop_data['Crop'] = crop_data['Crop'].astype(str)\n",
    "\n",
    "#     # Merge to get additional crop information if needed\n",
    "#     top_crops_info = crop_data.merge(top_crops, on='Crop', how='inner')\n",
    "\n",
    "#     # Check if the merge was successful\n",
    "#     if top_crops_info.empty:\n",
    "#         print(\"No matching crops found after merging. Please check the crop names.\")\n",
    "#     else:\n",
    "#         # Remove duplicates and sort the results\n",
    "#         top_crops_info = top_crops_info.drop_duplicates(subset='Crop', keep='first')\n",
    "#         top_crops_info = top_crops_info.sort_values(by='Probability', ascending=False)\n",
    "\n",
    "#         # Output the result\n",
    "#         print(top_crops_info[['Crop', 'Crop type', 'Probability']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2: Define conditions to filter crops based on region behavior\n",
    "# def filter_crops_by_region(crops_df, regions_df):\n",
    "#     # Define the columns to match\n",
    "#     common_columns = [\n",
    "#         'Altitude (masl)', 'temperature (C) ', 'pH', 'Humidity(%)', 'N', 'P', 'K'\n",
    "#     ]\n",
    "    \n",
    "#     # List to store matching crops\n",
    "#     matching_crops = []\n",
    "    \n",
    "#     for _, region_row in regions_df.iterrows():\n",
    "#         # Apply filters for each region's conditions\n",
    "#         filtered_crops = crops_df[\n",
    "#             (crops_df['Altitude (masl)'] >= region_row['Elevation'] - 100) &\n",
    "#             (crops_df['Altitude (masl)'] <= region_row['Elevation'] + 100) &\n",
    "#             (crops_df['temperature (C) '] >= region_row['Temperature (°C)'] - 2) &\n",
    "#             (crops_df['temperature (C) '] <= region_row['Temperature (°C)'] + 2) &\n",
    "#             (crops_df['pH'] >= region_row['pH_avg'] - 0.5) &\n",
    "#             (crops_df['pH'] <= region_row['pH_avg'] + 0.5) &\n",
    "#             (crops_df['Humidity(%)'] >= region_row['Humidity(%)'] - 5) &\n",
    "#             (crops_df['Humidity(%)'] <= region_row['Humidity(%)'] + 5) &\n",
    "#             (crops_df['N'] >= region_row['Nitrogen(%)'] - 10) &\n",
    "#             (crops_df['P'] >= region_row['Phosphorus(ppm)'] - 5) &\n",
    "#             (crops_df['K'] >= region_row['Potassium(ppm)'] - 5)\n",
    "#         ]\n",
    "        \n",
    "#         # Append matching crops to the list\n",
    "#         matching_crops.extend(filtered_crops['Crop'].unique())\n",
    "    \n",
    "#     return list(set(matching_crops))\n",
    "\n",
    "# # Step 3: Run the filtering function\n",
    "# matching_crops = filter_crops_by_region(sampled_dataset, region_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Filter the sampled_dataset for the matching crops\n",
    "# filtered_dataset = sampled_dataset[sampled_dataset['Crop'].isin(matching_crops)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 5: Visualize the matching crops based on attributes\n",
    "# def visualize_matching_crops(filtered_df):\n",
    "#     plt.figure(figsize=(12, 8))\n",
    "    \n",
    "#     # Visualize Altitude vs Temperature colored by Crop Type\n",
    "#     sns.scatterplot(\n",
    "#         data=filtered_df,\n",
    "#         x='Altitude (masl)',\n",
    "#         y='temperature (C) ',\n",
    "#         hue='Crop type',\n",
    "#         palette='viridis'\n",
    "#     )\n",
    "#     plt.title(\"Matching Crops: Altitude vs Temperature\")\n",
    "#     plt.xlabel(\"Altitude (masl)\")\n",
    "#     plt.ylabel(\"Temperature (C)\")\n",
    "#     plt.legend(title='Crop Type', bbox_to_anchor=(1, 1))\n",
    "#     plt.show()\n",
    "    \n",
    "#     # Box plot for pH levels across different crops\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     sns.boxplot(data=filtered_df, x='Crop', y='pH')\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.title(\"pH Levels of Matching Crops\")\n",
    "#     plt.ylabel(\"pH\")\n",
    "#     plt.xlabel(\"Crop\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 6: Visualize the filtered dataset\n",
    "# visualize_matching_crops(filtered_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_dataset.to_csv('filtered_sampled_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
