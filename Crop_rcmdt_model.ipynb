{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "mg2Iji4iZXe9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import joblib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "0yP_5YLaa8ZJ"
   },
   "outputs": [],
   "source": [
    "# crop_data = pd.read_excel('/content/drive/MyDrive/model dvpt data/crop_recommendation.xlsx', sheet_name=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "m-6QrBkja8Ht"
   },
   "outputs": [],
   "source": [
    "crop_data = pd.read_csv('dataset/filtered_crop_suitability_dataset.csv')\n",
    "region_data = pd.read_excel('dataset/crop_recommendations.xlsx', sheet_name=2)\n",
    "\n",
    "# crop_data = pd.read_excel('crop_recommendations.xlsx', sheet_name=0)\n",
    "# crop_data = pd.read_excel('/content/drive/MyDrive/model dvpt data/crop_recommendation2.xlsx', sheet_name=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "8czVMMVpePkX"
   },
   "outputs": [],
   "source": [
    "# # Function to sample a value from a range or threshold\n",
    "# def sample_from_range(value):\n",
    "#     # Remove commas from numbers\n",
    "#     if isinstance(value, str):\n",
    "#         value = value.replace(',', '')\n",
    "\n",
    "#     # Check if the value is a range (e.g., '45-60')\n",
    "#     if isinstance(value, str) and '-' in value:\n",
    "#         parts = value.split('-')\n",
    "#         if len(parts) == 2 and all(part.strip().replace('.', '', 1).isdigit() for part in parts):\n",
    "#             low, high = map(float, parts)\n",
    "#             return np.random.uniform(low, high)\n",
    "\n",
    "#     # Check for '>' or '<' in the value, e.g., '>60' or '<45'\n",
    "#     if isinstance(value, str) and value:\n",
    "#         if value[0] == '>':\n",
    "#             threshold = float(value[1:].strip())\n",
    "#             return np.random.uniform(threshold, threshold + 20)  # Sample within a range above the threshold\n",
    "#         elif value[0] == '<':\n",
    "#             threshold = float(value[1:].strip())\n",
    "#             return np.random.uniform(threshold - 20, threshold)  # Sample within a range below the threshold\n",
    "\n",
    "#     # Check for symbol at the end (e.g., '50<')\n",
    "#     if isinstance(value, str) and value[-1] == '<':\n",
    "#         threshold = float(value[:-1].strip())  # Remove the '<' symbol and convert to float\n",
    "#         return np.random.uniform(threshold - 20, threshold)  # Sample within a range below the threshold\n",
    "\n",
    "#     # Check if the value is a valid number after removing commas\n",
    "#     if isinstance(value, str) and value.replace('.', '', 1).isdigit():\n",
    "#         return float(value)  # Return as float after removing commas\n",
    "\n",
    "#     return value\n",
    "\n",
    "# # Function to generate samples for each crop\n",
    "# def generate_samples(data, num_samples=100):\n",
    "#     sampled_data = []\n",
    "#     for _, row in data.iterrows():\n",
    "#         for _ in range(num_samples):\n",
    "#             sampled_row = row.copy()\n",
    "#             sampled_row['Altitude (masl)'] = sample_from_range(row['Altitude (masl)'])\n",
    "#             sampled_row['temperature (C) '] = sample_from_range(row['temperature (C) '])\n",
    "#             sampled_row['pH'] = sample_from_range(row['pH'])\n",
    "#             sampled_row['Crop water need (mm/total growing period)'] = sample_from_range(row['Crop water need (mm/total growing period)'])\n",
    "#             sampled_row['Humidity(%)'] = sample_from_range(row['Humidity(%)'])\n",
    "#             sampled_row['N'] = sample_from_range(row['N'])\n",
    "#             sampled_row['P'] = sample_from_range(row['P'])\n",
    "#             sampled_row['K'] = sample_from_range(row['K'])\n",
    "#             sampled_data.append(sampled_row)\n",
    "#     return pd.DataFrame(sampled_data)\n",
    "\n",
    "# # Generate the new sampled dataset\n",
    "# sampled_dataset = generate_samples(crop_data, num_samples=100)\n",
    "sampled_dataset = crop_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "xj6wF6o2var0"
   },
   "outputs": [],
   "source": [
    "crop_columns_to_remove = [\n",
    "    'Id','Crop suitability','Growing period (days)','Irrigation required(%)'\n",
    "]\n",
    "\n",
    "sampled_dataset = sampled_dataset.drop(columns=crop_columns_to_remove, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "2S6Qq9DpJSRo"
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \n",
    "    'XGBoost': XGBClassifier(\n",
    "        n_estimators=200,                # Increase number of boosting rounds\n",
    "        learning_rate=0.05,              # Lower learning rate\n",
    "        max_depth=4,                     # Decrease max depth to avoid overfitting\n",
    "        min_child_weight=3,              # Minimum sum of instance weight needed in a child\n",
    "        gamma=0.1,                       # Minimum loss reduction required to split\n",
    "        subsample=0.8,                   # Fraction of samples used for training each tree\n",
    "        colsample_bytree=0.8,            # Fraction of features used for training each tree\n",
    "        reg_lambda=1.5,                  # L2 regularization\n",
    "        reg_alpha=0.5,                   # L1 regularization (adds sparsity)\n",
    "        eval_metric='mlogloss',\n",
    "        random_state=42\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "tk_vMDSqLVRF"
   },
   "outputs": [],
   "source": [
    "# Prepare the dataset for training\n",
    "train_features = sampled_dataset[['Altitude (masl)', 'temperature (C) ',\n",
    "                             'pH', 'N', 'P', 'K','Crop water need (mm/total growing period)', 'Humidity(%)']]\n",
    "target = sampled_dataset['Crop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "P6B3QEzqcXpr"
   },
   "outputs": [],
   "source": [
    "# Encode the target variable to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "target_encoded = label_encoder.fit_transform(target)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_features, target_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "e5H1DjfwdROn"
   },
   "outputs": [],
   "source": [
    "# Initialize model_accuracies\n",
    "model_accuracies = {name: [] for name in models.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gDYrzuCFcPwq",
    "outputId": "8295792e-80d4-493f-9de1-b6dd6169633a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost...\n",
      "\n",
      "XGBoost Accuracy: 0.9895\n",
      "\n",
      "Best Model: XGBoost with mean accuracy: 0.9895\n"
     ]
    }
   ],
   "source": [
    "# Function to train and evaluate models\n",
    "def train_and_evaluate(models, X_train, X_test, y_train, y_test):\n",
    "    results = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"Training {name}...\")\n",
    "        try:\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            print(f\"\\n{name} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "            # Calculate classification report\n",
    "            report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "            # Store results\n",
    "            results[name] = {\n",
    "                'model': model,\n",
    "                'accuracy': accuracy,\n",
    "                'classification_report': report\n",
    "            }\n",
    "\n",
    "            # Append the accuracy to the model_accuracies list\n",
    "            model_accuracies[name].append(accuracy)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error training {name}: {str(e)}\")\n",
    "            results[name] = {\n",
    "                'model': None,\n",
    "                'accuracy': None,\n",
    "                'classification_report': None,\n",
    "                'error': str(e)\n",
    "            }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Train and evaluate all models\n",
    "results = train_and_evaluate(models, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Calculate mean accuracies\n",
    "mean_accuracies = {\n",
    "    model_name: (sum(accuracies) / len(accuracies)) if len(accuracies) > 0 else 0\n",
    "    for model_name, accuracies in model_accuracies.items()\n",
    "}\n",
    "\n",
    "# Determine the best model\n",
    "best_model_name = max(mean_accuracies, key=mean_accuracies.get)\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name} with mean accuracy: {mean_accuracies[best_model_name]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "UywwCNDKcagp"
   },
   "outputs": [],
   "source": [
    "# sampled_dataset.to_csv('sampled_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "Y7_uO52eYOve"
   },
   "outputs": [],
   "source": [
    "# Step 1: Drop rows with specific unwanted text entries\n",
    "unwanted_text = ['Protected Land', 'Water Body']\n",
    "region_data = region_data[~region_data['pH'].isin(unwanted_text)]\n",
    "\n",
    "# Step 2: Function to calculate average pH\n",
    "def calculate_average_ph(ph_value):\n",
    "    # Handle special case for values like '<5.0'\n",
    "    if '<' in ph_value:\n",
    "        # Convert '<5.0' to 5.0 (assuming '<5.0' means \"up to 5.0\")\n",
    "        return float(ph_value.replace('<', ''))\n",
    "    elif '>' in ph_value:\n",
    "        return float(ph_value.replace('>',''))\n",
    "\n",
    "    # Handle range values like '6.0-7.0'\n",
    "    if '-' in ph_value:\n",
    "        lower, upper = map(float, ph_value.split('-'))\n",
    "        return (lower + upper) / 2\n",
    "\n",
    "    # Convert single numeric value to float\n",
    "    return float(ph_value)\n",
    "\n",
    "# Step 3: Apply the function to the 'pH' column\n",
    "region_data['pH_avg'] = region_data['pH'].apply(calculate_average_ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_crop_data(crop_names, dataset):\n",
    "    # Filter the dataset based on the crop names\n",
    "    filtered_data = dataset[dataset['Crop'].isin(crop_names)].drop_duplicates(subset=['Crop'])\n",
    "    \n",
    "    # Use a dictionary to store crop details for quick lookup\n",
    "    crop_details_dict = {}\n",
    "    for _, row in filtered_data.iterrows():\n",
    "        crop_details_dict[row['Crop']] = {\n",
    "            \"season_a_start\": row['Season A start(month)'],\n",
    "            \"season_a_end\": row['Season A end'],\n",
    "            \"season_b_start\": row['Season B start(month)'],\n",
    "            \"season_b_end\": row['Season B end(month)'],\n",
    "            \"soil_type\": row['Soil type']\n",
    "        }\n",
    "    \n",
    "    return crop_details_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "dGuk477Fm9yV"
   },
   "outputs": [],
   "source": [
    "# User input\n",
    "user_input = {\n",
    "    \"district\": \"Gasabo\",\n",
    "    \"sector\": \"Jali\",\n",
    "    \"start_date_to_plant\": \"2024-02-01\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"predicted_crops\": [\n",
      "        {\n",
      "            \"crop_name\": \"Spinach\",\n",
      "            \"probability\": 0.3290771543979645,\n",
      "            \"season_a_start\": 9,\n",
      "            \"season_a_end\": \"12-Nov\",\n",
      "            \"season_b_start\": 2,\n",
      "            \"season_b_end\": \"5-Apr\",\n",
      "            \"soil_type\": \"well-draining loamy soil\"\n",
      "        },\n",
      "        {\n",
      "            \"crop_name\": \"Tomato\",\n",
      "            \"probability\": 0.2253754585981369,\n",
      "            \"season_a_start\": 9,\n",
      "            \"season_a_end\": \"3-Jan\",\n",
      "            \"season_b_start\": 2,\n",
      "            \"season_b_end\": \"8-Jun\",\n",
      "            \"soil_type\": \"Well drained sandy, loam, and clay loam soils\"\n",
      "        },\n",
      "        {\n",
      "            \"crop_name\": \"Mango\",\n",
      "            \"probability\": 0.17884708940982819,\n",
      "            \"season_a_start\": 9,\n",
      "            \"season_a_end\": \"2-Dec\",\n",
      "            \"season_b_start\": 2,\n",
      "            \"season_b_end\": \"7-May\",\n",
      "            \"soil_type\": \" well-draining, sandy loam, loamy soil\"\n",
      "        },\n",
      "        {\n",
      "            \"crop_name\": \"Tea\",\n",
      "            \"probability\": 0.05703652650117874,\n",
      "            \"season_a_start\": 9,\n",
      "            \"season_a_end\": \"10-Sep\",\n",
      "            \"season_b_start\": 2,\n",
      "            \"season_b_end\": \"3-Feb\",\n",
      "            \"soil_type\": \"volcanic soil\"\n",
      "        },\n",
      "        {\n",
      "            \"crop_name\": \"Cabbage\",\n",
      "            \"probability\": 0.03619357571005821,\n",
      "            \"season_a_start\": 9,\n",
      "            \"season_a_end\": \"2-Jan\",\n",
      "            \"season_b_start\": 2,\n",
      "            \"season_b_end\": \"7-Jun\",\n",
      "            \"soil_type\": \"Well-drained sandy or silty loam\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Function to predict best crops based on input features\n",
    "def predict_best_crops(features, best_model, label_encoder, top_n=5):\n",
    "    # Convert features dictionary into a DataFrame for prediction\n",
    "    features_df = pd.DataFrame([features])\n",
    "\n",
    "    # Ensure the feature order matches what the model was trained on\n",
    "    feature_columns = [\n",
    "        'Altitude (masl)', 'temperature (C) ', 'pH', 'N', 'P', 'K', \n",
    "        'Crop water need (mm/total growing period)', 'Humidity(%)'\n",
    "    ]\n",
    "    features_df = features_df[feature_columns]\n",
    "    \n",
    "    # Make a prediction using the best model\n",
    "    try:\n",
    "        predictions_proba = best_model.predict_proba(features_df)[0]\n",
    "    except AttributeError:\n",
    "        predicted_class = best_model.predict(features_df)[0]\n",
    "        return [label_encoder.inverse_transform([predicted_class])[0]]\n",
    "\n",
    "    # Get the indices of the top N predictions with the highest probability\n",
    "    top_n_indices = np.argsort(predictions_proba)[-top_n:][::-1]\n",
    "\n",
    "    # Get the crop names and their corresponding probabilities\n",
    "    top_crops = label_encoder.inverse_transform(top_n_indices)\n",
    "    top_probabilities = predictions_proba[top_n_indices]\n",
    "\n",
    "    # Return both top crops and their probabilities\n",
    "    return list(zip(top_crops, top_probabilities))\n",
    "\n",
    "# Example: Filter region data based on user input\n",
    "filtered_region = region_data[\n",
    "    (region_data['District'] == user_input['district']) & \n",
    "    (region_data['Sector'] == user_input['sector'])\n",
    "]\n",
    "\n",
    "# Check if filtered_region is empty\n",
    "if filtered_region.empty:\n",
    "    print(\"No data found for the specified district and sector.\")\n",
    "else:\n",
    "    # Extract relevant features from filtered_region\n",
    "    humidity = filtered_region['Humidity(%)'].values[0]\n",
    "    temperature = filtered_region['Temperature (°C)'].values[0]\n",
    "    pH = filtered_region['pH_avg'].values[0]\n",
    "    potassium_min = filtered_region['Potassium(ppm)'].values[0]\n",
    "    phosphorus_min = filtered_region['Phosphorus(ppm)'].values[0]\n",
    "    nitrogen = filtered_region['Nitrogen(%)'].values[0]\n",
    "    crop_water_need = filtered_region['Average Rainfall (mm)'].values[0]\n",
    "    altitude = filtered_region['Elevation'].values[0]\n",
    "\n",
    "    # Prepare the features for the model\n",
    "    features = {\n",
    "        'Altitude (masl)': altitude,\n",
    "        'temperature (C) ': temperature,\n",
    "        'pH': pH,\n",
    "        'N': nitrogen,\n",
    "        'P': phosphorus_min,\n",
    "        'K': potassium_min,\n",
    "        'Crop water need (mm/total growing period)': crop_water_need,\n",
    "        'Humidity(%)': humidity\n",
    "    }\n",
    "\n",
    "    # Predict the top 5 crops along with their probabilities\n",
    "    top_crops = predict_best_crops(features, best_model, label_encoder)\n",
    "\n",
    "    # Extract crop names for querying additional data from the dataset\n",
    "    crop_names = [crop for crop, _ in top_crops]\n",
    "\n",
    "    # Fetch additional data for the predicted crops\n",
    "    crop_details = fetch_crop_data(crop_names, sampled_dataset)\n",
    "\n",
    "    # Format the output in JSON\n",
    "    output = {\n",
    "        \"predicted_crops\": [\n",
    "            {\n",
    "                \"crop_name\": crop,\n",
    "                \"probability\": float(probability),\n",
    "                **crop_details.get(crop, {})  # Merge details if available\n",
    "            }\n",
    "            for crop, probability in top_crops\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Print the output in JSON format\n",
    "    print(json.dumps(output, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_best_crops(features, best_model, label_encoder, top_n=5):\n",
    "    # Convert features dictionary into a DataFrame for prediction\n",
    "    features_df = pd.DataFrame([features])\n",
    "\n",
    "    # Ensure the feature order matches what the model was trained on\n",
    "    feature_columns = [\n",
    "        'Altitude (masl)', 'temperature (C) ', 'pH', 'N', 'P', 'K', \n",
    "        'Crop water need (mm/total growing period)', 'Humidity(%)'\n",
    "    ]\n",
    "    features_df = features_df[feature_columns]\n",
    "    \n",
    "    # Make a prediction using the best model\n",
    "    try:\n",
    "        predictions_proba = best_model.predict_proba(features_df)[0]\n",
    "    except AttributeError:\n",
    "        # If the model doesn't support predict_proba, fall back to predict\n",
    "        predicted_class = best_model.predict(features_df)[0]\n",
    "        return [label_encoder.inverse_transform([predicted_class])[0]]\n",
    "\n",
    "    # Get the indices of the top N predictions with the highest probability\n",
    "    top_n_indices = np.argsort(predictions_proba)[-top_n:][::-1]\n",
    "\n",
    "    # Get the crop names using the label encoder\n",
    "    top_crops = label_encoder.inverse_transform(top_n_indices)\n",
    "    \n",
    "    return top_crops\n",
    "\n",
    "# List to store the results for each sector\n",
    "results = []\n",
    "\n",
    "# Iterate over each sector in the region data\n",
    "for index, row in region_data.iterrows():\n",
    "    # Extract relevant features from each row\n",
    "    humidity = row['Humidity(%)']\n",
    "    temperature = row['Temperature (°C)']\n",
    "    pH = row['pH_avg']\n",
    "    potassium_min = row['Potassium(ppm)']\n",
    "    phosphorus_min = row['Phosphorus(ppm)']\n",
    "    nitrogen = row['Nitrogen(%)']\n",
    "    crop_water_need = row['Average Rainfall (mm)']\n",
    "    altitude = row['Elevation']\n",
    "    \n",
    "    # Prepare the features dictionary\n",
    "    features = {\n",
    "        'Altitude (masl)': altitude,\n",
    "        'temperature (C) ': temperature,\n",
    "        'pH': pH,\n",
    "        'N': nitrogen,\n",
    "        'P': phosphorus_min,\n",
    "        'K': potassium_min,\n",
    "        'Crop water need (mm/total growing period)': crop_water_need,\n",
    "        'Humidity(%)': humidity\n",
    "    }\n",
    "    \n",
    "    # Predict the top 5 crops for the current sector\n",
    "    top_crops = predict_best_crops(features, best_model, label_encoder)\n",
    "    \n",
    "    # Store the results (District, Sector, and top 5 crops)\n",
    "    results.append({\n",
    "        'District': row['District'],\n",
    "        'Sector': row['Sector'],\n",
    "        'Top 1 Crop': top_crops[0] if len(top_crops) > 0 else None,\n",
    "        'Top 2 Crop': top_crops[1] if len(top_crops) > 1 else None,\n",
    "        'Top 3 Crop': top_crops[2] if len(top_crops) > 2 else None,\n",
    "        'Top 4 Crop': top_crops[3] if len(top_crops) > 3 else None,\n",
    "        'Top 5 Crop': top_crops[4] if len(top_crops) > 4 else None\n",
    "    })\n",
    "\n",
    "# Convert the results list into a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_filename = 'best_crops_per_sector_DECISION_crops.csv'\n",
    "results_df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8RRJ7TC_nBSj",
    "outputId": "15749f81-e6dc-4f62-bf1b-94f33a4e4412"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Features: {'Altitude (masl)': 2049, 'temperature (C) ': 14.89676273, 'pH': 5.755, 'N': 100.5885138, 'P': 12.46373804, 'K': 47.92388791, 'Crop water need (mm/total growing period)': 1169.885808, 'Humidity(%)': 73.8558148}\n",
      "        Crop      Crop type  Probability\n",
      "300  Spinach    Leafy Green     0.329077\n",
      "100   Tomato      Vegetable     0.225375\n",
      "0      Mango          Fruit     0.178847\n",
      "400      Tea  Beverage Crop     0.057037\n",
      "200  Cabbage      Vegetable     0.036194\n"
     ]
    }
   ],
   "source": [
    "# Filter region data based on user input\n",
    "filtered_region = region_data[\n",
    "    (region_data['District'] == user_input['district']) &\n",
    "    (region_data['Sector'] == user_input['sector'])\n",
    "]\n",
    "\n",
    "# Check if filtered_region is empty\n",
    "if filtered_region.empty:\n",
    "    print(\"No data found for the specified district and sector.\")\n",
    "else:\n",
    "    # Extract relevant features from filtered_region\n",
    "    humidity = filtered_region['Humidity(%)'].values[0]\n",
    "    temperature = filtered_region['Temperature (°C)'].values[0]\n",
    "    pH = filtered_region['pH_avg'].values[0]\n",
    "    potassium_min = filtered_region['Potassium(ppm)'].values[0]\n",
    "    phosphorus_min = filtered_region['Phosphorus(ppm)'].values[0]\n",
    "    nitrogen = filtered_region['Nitrogen(%)'].values[0]\n",
    "    crop_water_need = filtered_region['Average Rainfall (mm)'].values[0]\n",
    "    altitude = filtered_region['Elevation'].values[0]\n",
    "\n",
    "    # Prepare the features for the model using user_input\n",
    "    features = {\n",
    "        'Altitude (masl)': altitude,\n",
    "        'temperature (C) ': temperature,\n",
    "        'pH': pH,\n",
    "        'N': nitrogen,\n",
    "        'P': phosphorus_min,\n",
    "        'K': potassium_min,\n",
    "        'Crop water need (mm/total growing period)': crop_water_need,\n",
    "        'Humidity(%)': humidity\n",
    "    }\n",
    "\n",
    "    print(\"Extracted Features:\", features)\n",
    "\n",
    "    # Convert features to DataFrame\n",
    "    input_data = pd.DataFrame([features])  # Wrap in a list to create a DataFrame\n",
    "\n",
    "    # Predict suitability for the input conditions using the best model\n",
    "    predictions = best_model.predict(input_data)\n",
    "\n",
    "    # Decode the predicted crop labels to their original string names\n",
    "    predictions_decoded = label_encoder.inverse_transform(predictions)\n",
    "\n",
    "    # Get predicted probabilities for all classes (crops)\n",
    "    predicted_probabilities = best_model.predict_proba(input_data)\n",
    "\n",
    "    # Decode the class names in the predicted probabilities\n",
    "    decoded_classes = label_encoder.inverse_transform(best_model.classes_)\n",
    "\n",
    "    # Create a DataFrame with decoded crops and their predicted probabilities\n",
    "    crop_probabilities = pd.DataFrame(predicted_probabilities, columns=decoded_classes)\n",
    "    crop_probabilities['Crop'] = predictions_decoded\n",
    "\n",
    "    # Remove duplicates based on Crop and the predicted probabilities\n",
    "    crop_probabilities = crop_probabilities.drop_duplicates(subset=['Crop'] + list(decoded_classes), keep='first')\n",
    "\n",
    "    # Select the probabilities for the first row only\n",
    "    first_row_probabilities = crop_probabilities.loc[0, decoded_classes]\n",
    "\n",
    "    # Ensure the series is numeric and call nlargest\n",
    "    first_row_probabilities = pd.to_numeric(first_row_probabilities, errors='coerce')\n",
    "\n",
    "    # Get the top crops based on predicted probabilities\n",
    "    top_crops = first_row_probabilities.nlargest(5).reset_index()\n",
    "    top_crops.columns = ['Crop', 'Probability']\n",
    "\n",
    "    # Decode the crop names\n",
    "    top_crops['Crop'] = top_crops['Crop'].astype(str)\n",
    "    crop_data['Crop'] = crop_data['Crop'].astype(str)\n",
    "\n",
    "    # Merge to get additional crop information if needed\n",
    "    top_crops_info = crop_data.merge(top_crops, on='Crop', how='inner')\n",
    "\n",
    "    # Check if the merge was successful\n",
    "    if top_crops_info.empty:\n",
    "        print(\"No matching crops found after merging. Please check the crop names.\")\n",
    "    else:\n",
    "        # Remove duplicates and sort the results\n",
    "        top_crops_info = top_crops_info.drop_duplicates(subset='Crop', keep='first')\n",
    "        top_crops_info = top_crops_info.sort_values(by='Probability', ascending=False)\n",
    "\n",
    "        # Output the result\n",
    "        print(top_crops_info[['Crop', 'Crop type', 'Probability']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2: Define conditions to filter crops based on region behavior\n",
    "# def filter_crops_by_region(crops_df, regions_df):\n",
    "#     # Define the columns to match\n",
    "#     common_columns = [\n",
    "#         'Altitude (masl)', 'temperature (C) ', 'pH', 'Humidity(%)', 'N', 'P', 'K'\n",
    "#     ]\n",
    "    \n",
    "#     # List to store matching crops\n",
    "#     matching_crops = []\n",
    "    \n",
    "#     for _, region_row in regions_df.iterrows():\n",
    "#         # Apply filters for each region's conditions\n",
    "#         filtered_crops = crops_df[\n",
    "#             (crops_df['Altitude (masl)'] >= region_row['Elevation'] - 100) &\n",
    "#             (crops_df['Altitude (masl)'] <= region_row['Elevation'] + 100) &\n",
    "#             (crops_df['temperature (C) '] >= region_row['Temperature (°C)'] - 2) &\n",
    "#             (crops_df['temperature (C) '] <= region_row['Temperature (°C)'] + 2) &\n",
    "#             (crops_df['pH'] >= region_row['pH_avg'] - 0.5) &\n",
    "#             (crops_df['pH'] <= region_row['pH_avg'] + 0.5) &\n",
    "#             (crops_df['Humidity(%)'] >= region_row['Humidity(%)'] - 5) &\n",
    "#             (crops_df['Humidity(%)'] <= region_row['Humidity(%)'] + 5) &\n",
    "#             (crops_df['N'] >= region_row['Nitrogen(%)'] - 10) &\n",
    "#             (crops_df['P'] >= region_row['Phosphorus(ppm)'] - 5) &\n",
    "#             (crops_df['K'] >= region_row['Potassium(ppm)'] - 5)\n",
    "#         ]\n",
    "        \n",
    "#         # Append matching crops to the list\n",
    "#         matching_crops.extend(filtered_crops['Crop'].unique())\n",
    "    \n",
    "#     return list(set(matching_crops))\n",
    "\n",
    "# # Step 3: Run the filtering function\n",
    "# matching_crops = filter_crops_by_region(sampled_dataset, region_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 4: Filter the sampled_dataset for the matching crops\n",
    "# filtered_dataset = sampled_dataset[sampled_dataset['Crop'].isin(matching_crops)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 5: Visualize the matching crops based on attributes\n",
    "# def visualize_matching_crops(filtered_df):\n",
    "#     plt.figure(figsize=(12, 8))\n",
    "    \n",
    "#     # Visualize Altitude vs Temperature colored by Crop Type\n",
    "#     sns.scatterplot(\n",
    "#         data=filtered_df,\n",
    "#         x='Altitude (masl)',\n",
    "#         y='temperature (C) ',\n",
    "#         hue='Crop type',\n",
    "#         palette='viridis'\n",
    "#     )\n",
    "#     plt.title(\"Matching Crops: Altitude vs Temperature\")\n",
    "#     plt.xlabel(\"Altitude (masl)\")\n",
    "#     plt.ylabel(\"Temperature (C)\")\n",
    "#     plt.legend(title='Crop Type', bbox_to_anchor=(1, 1))\n",
    "#     plt.show()\n",
    "    \n",
    "#     # Box plot for pH levels across different crops\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     sns.boxplot(data=filtered_df, x='Crop', y='pH')\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.title(\"pH Levels of Matching Crops\")\n",
    "#     plt.ylabel(\"pH\")\n",
    "#     plt.xlabel(\"Crop\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 6: Visualize the filtered dataset\n",
    "# visualize_matching_crops(filtered_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_dataset.to_csv('filtered_sampled_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
